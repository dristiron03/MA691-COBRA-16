{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:57.328228Z",
     "iopub.status.busy": "2021-11-18T18:25:57.327976Z",
     "iopub.status.idle": "2021-11-18T18:25:58.428761Z",
     "shell.execute_reply": "2021-11-18T18:25:58.428005Z",
     "shell.execute_reply.started": "2021-11-18T18:25:57.328196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import is_regressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble.forest import BaseForest\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.tree.tree import BaseDecisionTree\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils import check_X_y\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn import neighbors, tree, svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import math\n",
    "import random\n",
    "import logging\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.431070Z",
     "iopub.status.busy": "2021-11-18T18:25:58.430595Z",
     "iopub.status.idle": "2021-11-18T18:25:58.442718Z",
     "shell.execute_reply": "2021-11-18T18:25:58.441993Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.431031Z"
    }
   },
   "outputs": [],
   "source": [
    "class SMOTE(object):\n",
    "    \"\"\"Implementation of Synthetic Minority Over-Sampling Technique (SMOTE).\n",
    "    SMOTE performs oversampling of the minority class by picking target \n",
    "    minority class samples and their nearest minority class neighbors and \n",
    "    generating new samples that linearly combine features of each target \n",
    "    sample with features of its selected minority class neighbors [1].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k_neighbors : int, optional (default=5)\n",
    "        Number of nearest neighbors.\n",
    "    random_state : int or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator.\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by np.random.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] N. V. Chawla, K. W. Bowyer, L. O. Hall, and P. Kegelmeyer. \"SMOTE:\n",
    "           Synthetic Minority Over-Sampling Technique.\" Journal of Artificial\n",
    "           Intelligence Research (JAIR), 2002.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k_neighbors=5, random_state=None):\n",
    "        self.k = k_neighbors\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Train model based on input data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_minority_samples, n_features]\n",
    "            Holds the minority samples.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.n_minority_samples, self.n_features = self.X.shape\n",
    "\n",
    "        # Learn nearest neighbors.\n",
    "        self.neigh = NearestNeighbors(n_neighbors=self.k + 1)\n",
    "        self.neigh.fit(self.X)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def sample(self, n_samples):\n",
    "        \"\"\"Generate samples.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            Number of new synthetic samples.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        S : array, shape = [n_samples, n_features]\n",
    "            Returns synthetic samples.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed=self.random_state)\n",
    "        \n",
    "        S = np.zeros(shape=(n_samples, self.n_features))\n",
    "        \n",
    "        #Calculate synthetic samples.\n",
    "        for i in range(n_samples):\n",
    "            j = np.random.randint(0, self.X.shape[0])\n",
    "            \n",
    "            # Find the k NN for sample j.\n",
    "            # Exclude the sample itself.\n",
    "            nn = self.neigh.kneighbors(self.X[j].reshape(1, -1),\n",
    "                                       return_distance=False)[:, 1:]\n",
    "            nn_index = np.random.choice(nn[0])\n",
    "\n",
    "            diff = self.X[nn_index] - self.X[j]\n",
    "            gap = np.random.random()\n",
    "\n",
    "            S[i, :] = self.X[j, :] + gap * diff[:]\n",
    "        \n",
    "        return S\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.444518Z",
     "iopub.status.busy": "2021-11-18T18:25:58.444106Z",
     "iopub.status.idle": "2021-11-18T18:25:58.471217Z",
     "shell.execute_reply": "2021-11-18T18:25:58.470548Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.444482Z"
    }
   },
   "outputs": [],
   "source": [
    "class SMOTEBoost(AdaBoostClassifier):\n",
    "    \"\"\"Implementation of SMOTEBoost.\n",
    "    SMOTEBoost introduces data sampling into the AdaBoost algorithm by\n",
    "    oversampling the minority class using SMOTE on each boosting iteration [1].\n",
    "    This implementation inherits methods from the scikit-learn \n",
    "    AdaBoostClassifier class, only modifying the `fit` method.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int, optional (default=100)\n",
    "        Number of new synthetic samples per boosting step.\n",
    "    k_neighbors : int, optional (default=5)\n",
    "        Number of nearest neighbors.\n",
    "    base_estimator : object, optional (default=DecisionTreeClassifier)\n",
    "        The base estimator from which the boosted ensemble is built.\n",
    "        Support for sample weighting is required, as well as proper `classes_`\n",
    "        and `n_classes_` attributes.\n",
    "    n_estimators : int, optional (default=50)\n",
    "        The maximum number of estimators at which boosting is terminated.\n",
    "        In case of perfect fit, the learning procedure is stopped early.\n",
    "    learning_rate : float, optional (default=1.)\n",
    "        Learning rate shrinks the contribution of each classifier by\n",
    "        ``learning_rate``. There is a trade-off between ``learning_rate`` and\n",
    "        ``n_estimators``.\n",
    "    algorithm : {'SAMME', 'SAMME.R'}, optional (default='SAMME.R')\n",
    "        If 'SAMME.R' then use the SAMME.R real boosting algorithm.\n",
    "        ``base_estimator`` must support calculation of class probabilities.\n",
    "        If 'SAMME' then use the SAMME discrete boosting algorithm.\n",
    "        The SAMME.R algorithm typically converges faster than SAMME,\n",
    "        achieving a lower test error with fewer boosting iterations.\n",
    "    random_state : int or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator.\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by np.random.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] N. V. Chawla, A. Lazarevic, L. O. Hall, and K. W. Bowyer.\n",
    "           \"SMOTEBoost: Improving Prediction of the Minority Class in\n",
    "           Boosting.\" European Conference on Principles of Data Mining and\n",
    "           Knowledge Discovery (PKDD), 2003.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_samples=100,\n",
    "                 k_neighbors=5,\n",
    "                 base_estimator=None,\n",
    "                 n_estimators=50,\n",
    "                 learning_rate=1.,\n",
    "                 algorithm='SAMME.R',\n",
    "                 random_state=None):\n",
    "\n",
    "        self.n_samples = n_samples\n",
    "        self.algorithm = algorithm\n",
    "        self.smote = SMOTE(k_neighbors=k_neighbors,\n",
    "                           random_state=random_state)\n",
    "\n",
    "        super(SMOTEBoost, self).__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=random_state)\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, minority_target=None):\n",
    "        \"\"\"Build a boosted classifier/regressor from the training set (X, y),\n",
    "        performing SMOTE during each boosting step.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
    "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
    "            DOK, or LIL. COO, DOK, and LIL are converted to CSR. The dtype is\n",
    "            forced to DTYPE from tree._tree if the base classifier of this\n",
    "            ensemble weighted boosting classifier is a tree or forest.\n",
    "        y : array-like of shape = [n_samples]\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "        sample_weight : array-like of shape = [n_samples], optional\n",
    "            Sample weights. If None, the sample weights are initialized to\n",
    "            1 / n_samples.\n",
    "        minority_target : int\n",
    "            Minority class label.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        Notes\n",
    "        -----\n",
    "        Based on the scikit-learn v0.18 AdaBoostClassifier and\n",
    "        BaseWeightBoosting `fit` methods.\n",
    "        \"\"\"\n",
    "        # Check that algorithm is supported.\n",
    "        if self.algorithm not in ('SAMME', 'SAMME.R'):\n",
    "            raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n",
    "\n",
    "        # Check parameters.\n",
    "        if self.learning_rate <= 0:\n",
    "            raise ValueError(\"learning_rate must be greater than zero\")\n",
    "\n",
    "        if (self.base_estimator is None or\n",
    "                isinstance(self.base_estimator, (BaseDecisionTree,\n",
    "                                                 BaseForest))):\n",
    "            DTYPE = np.float64  # from fast_dict.pxd\n",
    "            dtype = DTYPE\n",
    "            accept_sparse = 'csc'\n",
    "        else:\n",
    "            dtype = None\n",
    "            accept_sparse = ['csr', 'csc']\n",
    "\n",
    "        X, y = check_X_y(X, y, accept_sparse=accept_sparse, dtype=dtype,\n",
    "                         y_numeric=is_regressor(self))\n",
    "\n",
    "        if sample_weight is None:\n",
    "            # Initialize weights to 1 / n_samples.\n",
    "            sample_weight = np.empty(X.shape[0], dtype=np.float64)\n",
    "            sample_weight[:] = 1. / X.shape[0]\n",
    "        else:\n",
    "            sample_weight = check_array(sample_weight, ensure_2d=False)\n",
    "            # Normalize existing weights.\n",
    "            sample_weight = sample_weight / sample_weight.sum(dtype=np.float64)\n",
    "\n",
    "            # Check that the sample weights sum is positive.\n",
    "            if sample_weight.sum() <= 0:\n",
    "                raise ValueError(\n",
    "                    \"Attempting to fit with a non-positive \"\n",
    "                    \"weighted number of samples.\")\n",
    "\n",
    "        if minority_target is None:\n",
    "            # Determine the minority class label.\n",
    "            stats_c_ = Counter(y)\n",
    "            maj_c_ = max(stats_c_, key=stats_c_.get)\n",
    "            min_c_ = min(stats_c_, key=stats_c_.get)\n",
    "            self.minority_target = min_c_\n",
    "        else:\n",
    "            self.minority_target = minority_target\n",
    "\n",
    "        # Check parameters.\n",
    "        self._validate_estimator()\n",
    "\n",
    "        # Clear any previous fit results.\n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n",
    "        self.estimator_errors_ = np.ones(self.n_estimators, dtype=np.float64)\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "\n",
    "        for iboost in range(self.n_estimators):\n",
    "            X_min = X[np.where(y == self.minority_target)]\n",
    "\n",
    "            # SMOTE step.\n",
    "            if len(X_min) >= self.smote.k:\n",
    "                self.smote.fit(X_min)\n",
    "                X_syn = self.smote.sample(self.n_samples)\n",
    "                y_syn = np.full(X_syn.shape[0], fill_value=self.minority_target,\n",
    "                                dtype=np.int64)\n",
    "\n",
    "                # Normalize synthetic sample weights based on current training set.\n",
    "                sample_weight_syn = np.empty(X_syn.shape[0], dtype=np.float64)\n",
    "                sample_weight_syn[:] = 1. / X.shape[0]\n",
    "\n",
    "                # Combine the original and synthetic samples.\n",
    "                X = np.vstack((X, X_syn))\n",
    "                y = np.append(y, y_syn)\n",
    "\n",
    "                # Combine the weights.\n",
    "                sample_weight = \\\n",
    "                    np.append(sample_weight, sample_weight_syn).reshape(-1, 1)\n",
    "                sample_weight = \\\n",
    "                    np.squeeze(normalize(sample_weight, axis=0, norm='l1'))\n",
    "\n",
    "                # X, y, sample_weight = shuffle(X, y, sample_weight,\n",
    "                #                              random_state=random_state)\n",
    "\n",
    "            # Boosting step.\n",
    "            sample_weight, estimator_weight, estimator_error = self._boost(\n",
    "                iboost,\n",
    "                X, y,\n",
    "                sample_weight,\n",
    "                random_state)\n",
    "\n",
    "            # Early termination.\n",
    "            if sample_weight is None:\n",
    "                break\n",
    "\n",
    "            self.estimator_weights_[iboost] = estimator_weight\n",
    "            self.estimator_errors_[iboost] = estimator_error\n",
    "\n",
    "            # Stop if error is zero.\n",
    "            if estimator_error == 0:\n",
    "                break\n",
    "\n",
    "            sample_weight_sum = np.sum(sample_weight)\n",
    "\n",
    "            # Stop if the sum of sample weights has become non-positive.\n",
    "            if sample_weight_sum <= 0:\n",
    "                break\n",
    "\n",
    "            if iboost < self.n_estimators - 1:\n",
    "                # Normalize.\n",
    "                sample_weight /= sample_weight_sum\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.474298Z",
     "iopub.status.busy": "2021-11-18T18:25:58.473527Z",
     "iopub.status.idle": "2021-11-18T18:25:58.515005Z",
     "shell.execute_reply": "2021-11-18T18:25:58.514319Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.474249Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('pycobra.classifiercobra')\n",
    "\n",
    "\n",
    "class ClassifierCobra(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Classification algorithm as introduced by\n",
    "    Mojirsheibani [1999] Combining Classifiers via Discretization,\n",
    "    Journal of the American Statistical Association.\n",
    "    Parameters\n",
    "    ----------\n",
    "    random_state: integer or a numpy.random.RandomState object.\n",
    "        Set the state of the random number generator to pass on to shuffle and loading machines, to ensure\n",
    "        reproducibility of your experiments, for example.\n",
    "    Attributes\n",
    "    ----------\n",
    "    machines: A dictionary which maps machine names to the machine objects.\n",
    "            The machine object must have a predict method for it to be used during aggregation.\n",
    "    machine_predictions: A dictionary which maps machine name to it's predictions over X_l\n",
    "            This value is used to determine which points from y_l are used to aggregate.\n",
    "    \"\"\"\n",
    "    def __init__(self, random_state=None, machine_list='basic'):\n",
    "        self.random_state = random_state\n",
    "        self.machine_list = machine_list\n",
    "\n",
    "    def fit(self, X, y, default=True, X_k=None, X_l=None, y_k=None, y_l=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_samples, n_features]\n",
    "            Training data which will be used to create ClassifierCobra.\n",
    "        y: array-like [n_samples]\n",
    "            Training labels for classification.\n",
    "        default: bool, optional\n",
    "            If set as true then sets up COBRA with default machines and splitting.\n",
    "        X_k : shape = [n_samples, n_features]\n",
    "            Training data which is used to train the machines loaded into COBRA.\n",
    "        y_k : array-like, shape = [n_samples]\n",
    "            Target values used to train the machines loaded into COBRA.\n",
    "        X_l : shape = [n_samples, n_features]\n",
    "            Training data which is used during the aggregation of COBRA.\n",
    "        y_l : array-like, shape = [n_samples]\n",
    "            Target values which are actually used in the aggregation of COBRA.\n",
    "        \"\"\"\n",
    "\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.X_k_ = X_k\n",
    "        self.X_l_ = X_l\n",
    "        self.y_k_ = y_k\n",
    "        self.y_l_ = y_l\n",
    "        self.estimators_ = {}\n",
    "\n",
    "        # try block to pass scikit-learn estimator check.\n",
    "        try:\n",
    "            # set-up COBRA with default machines\n",
    "            if default:\n",
    "                self.split_data()\n",
    "                self.load_default(machine_list=self.machine_list)\n",
    "                self.load_machine_predictions()\n",
    "        except ValueError:\n",
    "            return self\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def pred(self, X, M, info=False):\n",
    "        \"\"\"\n",
    "        Performs the CLassififerCobra aggregation scheme, used in predict method.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        M: int, optional\n",
    "            M refers to the number of machines the prediction must be close to to be considered during aggregation.\n",
    "        info: boolean, optional\n",
    "            If info is true the list of points selected in the aggregation is returned.\n",
    "        Returns\n",
    "        -------\n",
    "        result: prediction\n",
    "        \"\"\"\n",
    "\n",
    "        # dictionary mapping machine to points selected\n",
    "        select = {}\n",
    "        for machine in self.estimators_:\n",
    "            # machine prediction\n",
    "            label = self.estimators_[machine].predict(X)\n",
    "            select[machine] = set()\n",
    "            # iterating from l to n\n",
    "            # replace with numpy iteration\n",
    "            for count in range(0, len(self.X_l_)):\n",
    "                if self.machine_predictions_[machine][count] == label:\n",
    "                    select[machine].add(count)\n",
    "\n",
    "        points = []\n",
    "        # count is the indice number.\n",
    "        for count in range(0, len(self.X_l_)):\n",
    "            # row check is number of machines which picked up a particular point\n",
    "            row_check = 0\n",
    "            for machine in select:\n",
    "                if count in select[machine]:\n",
    "                    row_check += 1\n",
    "            if row_check == M:\n",
    "                points.append(count)\n",
    "\n",
    "        # if no points are selected, return 0\n",
    "        if len(points) == 0:\n",
    "            if info:\n",
    "                logger.info(\"No points were selected, prediction is 0\")\n",
    "                return (0, 0)\n",
    "            logger.info(\"No points were selected, prediction is 0\")\n",
    "            return 0\n",
    "\n",
    "        # aggregate\n",
    "        classes = {}\n",
    "        for label in np.unique(self.y_l_):\n",
    "            classes[label] = 0\n",
    "\n",
    "        for point in points:\n",
    "            classes[self.y_l_[point]] += 1\n",
    "\n",
    "        result = int(max(classes, key=classes.get))\n",
    "        if info:\n",
    "            return result, points\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict(self, X, M=None, info=False):\n",
    "        \"\"\"\n",
    "        Performs the ClassifierCobra aggregation scheme, calls pred.\n",
    "        ClassifierCobra performs a majority vote among all points which are retained by the COBRA procedure.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        M: int, optional\n",
    "            M refers to the number of machines the prediction must be close to to be considered during aggregation.\n",
    "        info: boolean, optional\n",
    "            If info is true the list of points selected in the aggregation is returned.\n",
    "        Returns\n",
    "        -------\n",
    "        result: prediction\n",
    "        \"\"\"\n",
    "        X = check_array(X)\n",
    "\n",
    "        if M is None:\n",
    "            M = len(self.estimators_)\n",
    "        if X.ndim == 1:\n",
    "            return self.pred(X.reshape(1, -1), M=M)\n",
    "\n",
    "        result = np.zeros(len(X))\n",
    "        avg_points = 0\n",
    "        index = 0\n",
    "        for vector in X:\n",
    "            if info:\n",
    "                result[index], points = self.pred(vector.reshape(1, -1), M=M, info=info)\n",
    "                avg_points += len(points)\n",
    "            else:\n",
    "                result[index] = self.pred(vector.reshape(1, -1), M=M)\n",
    "            index += 1\n",
    "        \n",
    "        if info:\n",
    "            avg_points = avg_points / len(X_array)\n",
    "            return result, avg_points\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict_proba(self, X, kernel=None, metric=None, bandwidth=1, **kwargs): \n",
    "        \"\"\"\n",
    "        Performs the ClassifierCobra aggregation scheme and calculates probability of a point being in a particular class.\n",
    "        ClassifierCobra performs a majority vote among all points which are retained by the COBRA procedure.\n",
    "        \n",
    "        NOTE: this method is to visualise boundaries.\n",
    "        The current method is just the mean of the consituent machines, as the concept of that kind of predicted probability\n",
    "        doesn't exist (yet) for classifier cobra.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        \"\"\"\n",
    "\n",
    "        probs = []\n",
    "        for machine in self.estimators_:\n",
    "            try:\n",
    "                probs.append(self.estimators_[machine].predict_proba(X))\n",
    "            except AttributeError:\n",
    "                continue\n",
    "        prob = np.mean(probs, axis=0)\n",
    "        return prob\n",
    "\n",
    "\n",
    "    def split_data(self, k=None, l=None, shuffle_data=True):\n",
    "        \"\"\"\n",
    "        Split the data into different parts for training machines and for aggregation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, optional\n",
    "            k is the number of points used to train the machines.\n",
    "            Those are the first k points of the data provided.\n",
    "        l: int, optional\n",
    "            l is the number of points used to form the ClassifierCobra aggregate.\n",
    "        shuffle: bool, optional\n",
    "            Boolean value to decide to shuffle the data before splitting.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        if shuffle_data:\n",
    "            self.X_, self.y_ = shuffle(self.X_, self.y_, random_state=self.random_state)\n",
    "\n",
    "        if k is None and l is None:\n",
    "            k = int(len(self.X_) / 2)\n",
    "            l = int(len(self.X_))\n",
    "\n",
    "        if k is not None and l is None:\n",
    "            l = len(self.X_) - k\n",
    "\n",
    "        if l is not None and k is None:\n",
    "            k = len(self.X_) - l\n",
    "\n",
    "        self.X_k_ = self.X_[:k]\n",
    "        self.X_l_ = self.X_[k:l]\n",
    "        self.y_k_ = self.y_[:k]\n",
    "        self.y_l_ = self.y_[k:l]\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_default(self, machine_list='basic'):\n",
    "        \"\"\"\n",
    "        Loads 4 different scikit-learn regressors by default. The advanced list adds more machines. \n",
    "        As of current release SGD algorithm is not included in the advanced list.\n",
    "        Parameters\n",
    "        ----------\n",
    "        machine_list: optional, list of strings\n",
    "            List of default machine names to be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        if machine_list == 'basic':\n",
    "            machine_list = ['sgd', 'tree', 'knn', 'svm']\n",
    "        if machine_list == 'advanced':\n",
    "            machine_list = ['tree', 'knn', 'svm', 'logreg', 'naive_bayes', 'lda', 'neural_network']\n",
    "        if machine_list == 'cobra':\n",
    "            machine_list = ['cobra', 'tree', 'sgd', 'knn', 'svm']\n",
    "\n",
    "        for machine in machine_list:\n",
    "            try:\n",
    "                if machine == 'svm':\n",
    "                    self.estimators_['svm'] = svm.SVC().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'knn':\n",
    "                    self.estimators_['knn'] = neighbors.KNeighborsClassifier().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'tree':\n",
    "                    self.estimators_['tree'] = tree.DecisionTreeClassifier().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'logreg':\n",
    "                    self.estimators_['logreg'] = LogisticRegression(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'naive_bayes':\n",
    "                    self.estimators_['naive_bayes'] = GaussianNB().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'lda':\n",
    "                    self.estimators_['lda'] = LinearDiscriminantAnalysis().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'neural_network':\n",
    "                    self.estimators_['neural_network'] = MLPClassifier(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'cobra':\n",
    "                    self.estimators_['cobra'] = SMOTEBoost().fit(self.X_k_, self.y_k_)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine(self, machine_name, machine):\n",
    "        \"\"\"\n",
    "        Adds a machine to be used during the aggregation strategy.\n",
    "        The machine object must have been trained using X_k and y_k, and must have a 'predict()' method.\n",
    "        After the machine is loaded, for it to be used during aggregation, load_machine_predictions must be run.\n",
    "        Parameters\n",
    "        ----------\n",
    "        machine_name : string\n",
    "            Name of the machine you are loading\n",
    "        machine: machine/regressor object\n",
    "            The regressor machine object which is mapped to the machine_name\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        self.estimators_[machine_name] = machine\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine_predictions(self, predictions=None):\n",
    "        \"\"\"\n",
    "        Stores the trained machines' predicitons on D_l in a dictionary, to be used for predictions.\n",
    "        Should be run after all the machines to be used for aggregation is loaded.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions: dictionary, optional\n",
    "            A pre-existing machine:predictions dictionary can also be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        self.machine_predictions_ = {}\n",
    "        if predictions is None:\n",
    "            for machine in self.estimators_:\n",
    "                self.machine_predictions_[machine] = self.estimators_[machine].predict(self.X_l_)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine_proba_predictions(self, predictions=None):\n",
    "        \"\"\"\n",
    "        Stores the trained machines' predicitons on D_l in a dictionary, to be used for predictions.\n",
    "        Should be run after all the machines to be used for aggregation is loaded.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions: dictionary, optional\n",
    "            A pre-existing machine:predictions dictionary can also be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        self.machine_proba_predictions_ = {}\n",
    "        if predictions is None:\n",
    "            for machine in self.estimators_:\n",
    "                try:\n",
    "                    self.machine_proba_predictions_[machine] = self.estimators_[machine].predict_proba(self.X_l_)\n",
    "                except AttributeError:\n",
    "                    self.machine_proba_predictions_[machine] = self.estimators_[machine].decision_function(self.X_l_)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.773066Z",
     "iopub.status.busy": "2021-11-18T18:25:58.772676Z",
     "iopub.status.idle": "2021-11-18T18:26:07.733253Z",
     "shell.execute_reply": "2021-11-18T18:26:07.732122Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.773035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pycobra\n",
      "  Downloading pycobra-0.2.5-py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from pycobra) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from pycobra) (0.23.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from pycobra) (3.4.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from pycobra) (1.3.4)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from pycobra) (1.19.5)\n",
      "Requirement already satisfied: seaborn in /opt/conda/lib/python3.7/site-packages (from pycobra) (0.11.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycobra) (2.8.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycobra) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycobra) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycobra) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->pycobra) (1.3.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->pycobra) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->pycobra) (2021.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pycobra) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->pycobra) (2.2.0)\n",
      "Installing collected packages: pycobra\n",
      "Successfully installed pycobra-0.2.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# from pycobra.classifiercobra import ClassifierCobra\n",
    "%pip install pycobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.742436Z",
     "iopub.status.busy": "2021-11-18T18:26:07.740719Z",
     "iopub.status.idle": "2021-11-18T18:26:07.750399Z",
     "shell.execute_reply": "2021-11-18T18:26:07.749211Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.742389Z"
    }
   },
   "outputs": [],
   "source": [
    "# from pycobra.classifiercobra import ClassifierCobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.752542Z",
     "iopub.status.busy": "2021-11-18T18:26:07.752223Z",
     "iopub.status.idle": "2021-11-18T18:26:07.763134Z",
     "shell.execute_reply": "2021-11-18T18:26:07.762019Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.752501Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(ClassifierCobra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.767124Z",
     "iopub.status.busy": "2021-11-18T18:26:07.766752Z",
     "iopub.status.idle": "2021-11-18T18:26:07.882884Z",
     "shell.execute_reply": "2021-11-18T18:26:07.882190Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.767087Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data[:-20]\n",
    "y = bc.target[:-20]\n",
    "X_test = bc.data[-20:]\n",
    "y_test = bc.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.884602Z",
     "iopub.status.busy": "2021-11-18T18:26:07.884167Z",
     "iopub.status.idle": "2021-11-18T18:26:07.888559Z",
     "shell.execute_reply": "2021-11-18T18:26:07.887586Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.884566Z"
    }
   },
   "outputs": [],
   "source": [
    "cc = ClassifierCobra(machine_list='basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.890539Z",
     "iopub.status.busy": "2021-11-18T18:26:07.889963Z",
     "iopub.status.idle": "2021-11-18T18:26:08.038051Z",
     "shell.execute_reply": "2021-11-18T18:26:08.037271Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.890504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "cc.fit(X, y)\n",
    "f1_score(y_test, cc.predict(X_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:08.039711Z",
     "iopub.status.busy": "2021-11-18T18:26:08.039295Z",
     "iopub.status.idle": "2021-11-18T18:26:11.335207Z",
     "shell.execute_reply": "2021-11-18T18:26:11.334305Z",
     "shell.execute_reply.started": "2021-11-18T18:26:08.039676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../input/creditcardfraud/creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.337009Z",
     "iopub.status.busy": "2021-11-18T18:26:11.336685Z",
     "iopub.status.idle": "2021-11-18T18:26:11.379326Z",
     "shell.execute_reply": "2021-11-18T18:26:11.378581Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.336968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.382118Z",
     "iopub.status.busy": "2021-11-18T18:26:11.381580Z",
     "iopub.status.idle": "2021-11-18T18:26:11.391612Z",
     "shell.execute_reply": "2021-11-18T18:26:11.390711Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.382078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.393876Z",
     "iopub.status.busy": "2021-11-18T18:26:11.393265Z",
     "iopub.status.idle": "2021-11-18T18:26:11.761794Z",
     "shell.execute_reply": "2021-11-18T18:26:11.760991Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.393839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.918649e-15</td>\n",
       "      <td>5.682686e-16</td>\n",
       "      <td>-8.761736e-15</td>\n",
       "      <td>2.811118e-15</td>\n",
       "      <td>-1.552103e-15</td>\n",
       "      <td>2.040130e-15</td>\n",
       "      <td>-1.698953e-15</td>\n",
       "      <td>-1.893285e-16</td>\n",
       "      <td>-3.147640e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.473120e-16</td>\n",
       "      <td>8.042109e-16</td>\n",
       "      <td>5.282512e-16</td>\n",
       "      <td>4.456271e-15</td>\n",
       "      <td>1.426896e-15</td>\n",
       "      <td>1.701640e-15</td>\n",
       "      <td>-3.662252e-16</td>\n",
       "      <td>-1.217809e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.918649e-15  5.682686e-16 -8.761736e-15  2.811118e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552103e-15  2.040130e-15 -1.698953e-15 -1.893285e-16 -3.147640e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.473120e-16  8.042109e-16  5.282512e-16  4.456271e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.426896e-15  1.701640e-15 -3.662252e-16 -1.217809e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.764020Z",
     "iopub.status.busy": "2021-11-18T18:26:11.763477Z",
     "iopub.status.idle": "2021-11-18T18:26:11.791112Z",
     "shell.execute_reply": "2021-11-18T18:26:11.790308Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.763975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.792931Z",
     "iopub.status.busy": "2021-11-18T18:26:11.792606Z",
     "iopub.status.idle": "2021-11-18T18:26:11.802921Z",
     "shell.execute_reply": "2021-11-18T18:26:11.802209Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.792888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.805144Z",
     "iopub.status.busy": "2021-11-18T18:26:11.804625Z",
     "iopub.status.idle": "2021-11-18T18:26:12.004831Z",
     "shell.execute_reply": "2021-11-18T18:26:12.004167Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.805106Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('Class', data=df)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:12.007388Z",
     "iopub.status.busy": "2021-11-18T18:26:12.007095Z",
     "iopub.status.idle": "2021-11-18T18:26:15.572844Z",
     "shell.execute_reply": "2021-11-18T18:26:15.572172Z",
     "shell.execute_reply.started": "2021-11-18T18:26:12.007351Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/conda/lib/python3.7/site-packages/seaborn/distributions.py:2619: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "amount_val = df['Amount'].values\n",
    "time_val = df['Time'].values\n",
    "\n",
    "sns.distplot(amount_val, ax=ax[0], color='r')\n",
    "ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
    "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "sns.distplot(time_val, ax=ax[1], color='b')\n",
    "ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
    "ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:00.907967Z",
     "iopub.status.busy": "2021-11-18T18:30:00.907161Z",
     "iopub.status.idle": "2021-11-18T18:30:01.005868Z",
     "shell.execute_reply": "2021-11-18T18:30:01.005093Z",
     "shell.execute_reply.started": "2021-11-18T18:30:00.907917Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:01.538552Z",
     "iopub.status.busy": "2021-11-18T18:30:01.538245Z",
     "iopub.status.idle": "2021-11-18T18:30:01.590942Z",
     "shell.execute_reply": "2021-11-18T18:30:01.590175Z",
     "shell.execute_reply.started": "2021-11-18T18:30:01.538524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Amount and Time are Scaled!\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:02.750482Z",
     "iopub.status.busy": "2021-11-18T18:30:02.749820Z",
     "iopub.status.idle": "2021-11-18T18:30:02.906210Z",
     "shell.execute_reply": "2021-11-18T18:30:02.905394Z",
     "shell.execute_reply.started": "2021-11-18T18:30:02.750444Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(df.drop('Class', axis=1),\n",
    "                                                 df['Class'],\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:04.152588Z",
     "iopub.status.busy": "2021-11-18T18:30:04.152164Z",
     "iopub.status.idle": "2021-11-18T18:30:04.156576Z",
     "shell.execute_reply": "2021-11-18T18:30:04.155700Z",
     "shell.execute_reply.started": "2021-11-18T18:30:04.152549Z"
    }
   },
   "outputs": [],
   "source": [
    "cc = ClassifierCobra(machine_list='cobra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:15.687990Z",
     "iopub.status.busy": "2021-11-18T18:26:15.687699Z",
     "iopub.status.idle": "2021-11-18T18:29:52.683344Z",
     "shell.execute_reply": "2021-11-18T18:29:52.682185Z",
     "shell.execute_reply.started": "2021-11-18T18:26:15.687953Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_34/175308802.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_34/441814092.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, M, info)\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mavg_points\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_34/441814092.py\u001b[0m in \u001b[0;36mpred\u001b[0;34m(self, X, M, info)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mrow_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mmachine\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselect\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmachine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m                     \u001b[0mrow_check\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mrow_check\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cc.fit(X, y)\n",
    "f1_score(y_test, cc.predict(x_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
