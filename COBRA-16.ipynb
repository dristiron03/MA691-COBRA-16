{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:57.328228Z",
     "iopub.status.busy": "2021-11-18T18:25:57.327976Z",
     "iopub.status.idle": "2021-11-18T18:25:58.428761Z",
     "shell.execute_reply": "2021-11-18T18:25:58.428005Z",
     "shell.execute_reply.started": "2021-11-18T18:25:57.328196Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.ensemble.forest module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.ensemble. Anything that cannot be imported from sklearn.ensemble is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "C:\\Users\\Hp\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.tree.tree module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.tree. Anything that cannot be imported from sklearn.tree is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.base import is_regressor\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble.forest import BaseForest\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.tree.tree import BaseDecisionTree\n",
    "from sklearn.utils import check_random_state\n",
    "from sklearn.utils import check_X_y\n",
    "#from sklearn.utils import shuffle\n",
    "\n",
    "from sklearn import neighbors, tree, svm\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import math\n",
    "import random\n",
    "import logging\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.431070Z",
     "iopub.status.busy": "2021-11-18T18:25:58.430595Z",
     "iopub.status.idle": "2021-11-18T18:25:58.442718Z",
     "shell.execute_reply": "2021-11-18T18:25:58.441993Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.431031Z"
    }
   },
   "outputs": [],
   "source": [
    "class SMOTE(object):\n",
    "    \"\"\"Implementation of Synthetic Minority Over-Sampling Technique (SMOTE).\n",
    "    SMOTE performs oversampling of the minority class by picking target \n",
    "    minority class samples and their nearest minority class neighbors and \n",
    "    generating new samples that linearly combine features of each target \n",
    "    sample with features of its selected minority class neighbors [1].\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    k_neighbors : int, optional (default=5)\n",
    "        Number of nearest neighbors.\n",
    "    random_state : int or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator.\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by np.random.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] N. V. Chawla, K. W. Bowyer, L. O. Hall, and P. Kegelmeyer. \"SMOTE:\n",
    "           Synthetic Minority Over-Sampling Technique.\" Journal of Artificial\n",
    "           Intelligence Research (JAIR), 2002.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, k_neighbors=5, random_state=None):\n",
    "        self.k = k_neighbors\n",
    "        self.random_state = random_state\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \"\"\"Train model based on input data.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like, shape = [n_minority_samples, n_features]\n",
    "            Holds the minority samples.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.n_minority_samples, self.n_features = self.X.shape\n",
    "\n",
    "        # Learn nearest neighbors.\n",
    "        self.neigh = NearestNeighbors(n_neighbors=self.k + 1)\n",
    "        self.neigh.fit(self.X)\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def sample(self, n_samples):\n",
    "        \"\"\"Generate samples.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            Number of new synthetic samples.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        S : array, shape = [n_samples, n_features]\n",
    "            Returns synthetic samples.\n",
    "        \"\"\"\n",
    "        np.random.seed(seed=self.random_state)\n",
    "        \n",
    "        S = np.zeros(shape=(n_samples, self.n_features))\n",
    "        \n",
    "        #Calculate synthetic samples.\n",
    "        for i in range(n_samples):\n",
    "            j = np.random.randint(0, self.X.shape[0])\n",
    "            \n",
    "            # Find the k NN for sample j.\n",
    "            # Exclude the sample itself.\n",
    "            nn = self.neigh.kneighbors(self.X[j].reshape(1, -1),\n",
    "                                       return_distance=False)[:, 1:]\n",
    "            nn_index = np.random.choice(nn[0])\n",
    "\n",
    "            diff = self.X[nn_index] - self.X[j]\n",
    "            gap = np.random.random()\n",
    "\n",
    "            S[i, :] = self.X[j, :] + gap * diff[:]\n",
    "        \n",
    "        return S\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.444518Z",
     "iopub.status.busy": "2021-11-18T18:25:58.444106Z",
     "iopub.status.idle": "2021-11-18T18:25:58.471217Z",
     "shell.execute_reply": "2021-11-18T18:25:58.470548Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.444482Z"
    }
   },
   "outputs": [],
   "source": [
    "class SMOTEBoost(AdaBoostClassifier):\n",
    "    \"\"\"Implementation of SMOTEBoost.\n",
    "    SMOTEBoost introduces data sampling into the AdaBoost algorithm by\n",
    "    oversampling the minority class using SMOTE on each boosting iteration [1].\n",
    "    This implementation inherits methods from the scikit-learn \n",
    "    AdaBoostClassifier class, only modifying the `fit` method.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_samples : int, optional (default=100)\n",
    "        Number of new synthetic samples per boosting step.\n",
    "    k_neighbors : int, optional (default=5)\n",
    "        Number of nearest neighbors.\n",
    "    base_estimator : object, optional (default=DecisionTreeClassifier)\n",
    "        The base estimator from which the boosted ensemble is built.\n",
    "        Support for sample weighting is required, as well as proper `classes_`\n",
    "        and `n_classes_` attributes.\n",
    "    n_estimators : int, optional (default=50)\n",
    "        The maximum number of estimators at which boosting is terminated.\n",
    "        In case of perfect fit, the learning procedure is stopped early.\n",
    "    learning_rate : float, optional (default=1.)\n",
    "        Learning rate shrinks the contribution of each classifier by\n",
    "        ``learning_rate``. There is a trade-off between ``learning_rate`` and\n",
    "        ``n_estimators``.\n",
    "    algorithm : {'SAMME', 'SAMME.R'}, optional (default='SAMME.R')\n",
    "        If 'SAMME.R' then use the SAMME.R real boosting algorithm.\n",
    "        ``base_estimator`` must support calculation of class probabilities.\n",
    "        If 'SAMME' then use the SAMME discrete boosting algorithm.\n",
    "        The SAMME.R algorithm typically converges faster than SAMME,\n",
    "        achieving a lower test error with fewer boosting iterations.\n",
    "    random_state : int or None, optional (default=None)\n",
    "        If int, random_state is the seed used by the random number generator.\n",
    "        If None, the random number generator is the RandomState instance used\n",
    "        by np.random.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] N. V. Chawla, A. Lazarevic, L. O. Hall, and K. W. Bowyer.\n",
    "           \"SMOTEBoost: Improving Prediction of the Minority Class in\n",
    "           Boosting.\" European Conference on Principles of Data Mining and\n",
    "           Knowledge Discovery (PKDD), 2003.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 n_samples=100,\n",
    "                 k_neighbors=5,\n",
    "                 base_estimator=None,\n",
    "                 n_estimators=50,\n",
    "                 learning_rate=1.,\n",
    "                 algorithm='SAMME.R',\n",
    "                 random_state=None):\n",
    "\n",
    "        self.n_samples = n_samples\n",
    "        self.algorithm = algorithm\n",
    "        self.smote = SMOTE(k_neighbors=k_neighbors,\n",
    "                           random_state=random_state)\n",
    "\n",
    "        super(SMOTEBoost, self).__init__(\n",
    "            base_estimator=base_estimator,\n",
    "            n_estimators=n_estimators,\n",
    "            learning_rate=learning_rate,\n",
    "            random_state=random_state)\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None, minority_target=None):\n",
    "        \"\"\"Build a boosted classifier/regressor from the training set (X, y),\n",
    "        performing SMOTE during each boosting step.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix} of shape = [n_samples, n_features]\n",
    "            The training input samples. Sparse matrix can be CSC, CSR, COO,\n",
    "            DOK, or LIL. COO, DOK, and LIL are converted to CSR. The dtype is\n",
    "            forced to DTYPE from tree._tree if the base classifier of this\n",
    "            ensemble weighted boosting classifier is a tree or forest.\n",
    "        y : array-like of shape = [n_samples]\n",
    "            The target values (class labels in classification, real numbers in\n",
    "            regression).\n",
    "        sample_weight : array-like of shape = [n_samples], optional\n",
    "            Sample weights. If None, the sample weights are initialized to\n",
    "            1 / n_samples.\n",
    "        minority_target : int\n",
    "            Minority class label.\n",
    "        Returns\n",
    "        -------\n",
    "        self : object\n",
    "            Returns self.\n",
    "        Notes\n",
    "        -----\n",
    "        Based on the scikit-learn v0.18 AdaBoostClassifier and\n",
    "        BaseWeightBoosting `fit` methods.\n",
    "        \"\"\"\n",
    "        # Check that algorithm is supported.\n",
    "        if self.algorithm not in ('SAMME', 'SAMME.R'):\n",
    "            raise ValueError(\"algorithm %s is not supported\" % self.algorithm)\n",
    "\n",
    "        # Check parameters.\n",
    "        if self.learning_rate <= 0:\n",
    "            raise ValueError(\"learning_rate must be greater than zero\")\n",
    "\n",
    "        if (self.base_estimator is None or\n",
    "                isinstance(self.base_estimator, (BaseDecisionTree,\n",
    "                                                 BaseForest))):\n",
    "            DTYPE = np.float64  # from fast_dict.pxd\n",
    "            dtype = DTYPE\n",
    "            accept_sparse = 'csc'\n",
    "        else:\n",
    "            dtype = None\n",
    "            accept_sparse = ['csr', 'csc']\n",
    "\n",
    "        X, y = check_X_y(X, y, accept_sparse=accept_sparse, dtype=dtype,\n",
    "                         y_numeric=is_regressor(self))\n",
    "\n",
    "        if sample_weight is None:\n",
    "            # Initialize weights to 1 / n_samples.\n",
    "            sample_weight = np.empty(X.shape[0], dtype=np.float64)\n",
    "            sample_weight[:] = 1. / X.shape[0]\n",
    "        else:\n",
    "            sample_weight = check_array(sample_weight, ensure_2d=False)\n",
    "            # Normalize existing weights.\n",
    "            sample_weight = sample_weight / sample_weight.sum(dtype=np.float64)\n",
    "\n",
    "            # Check that the sample weights sum is positive.\n",
    "            if sample_weight.sum() <= 0:\n",
    "                raise ValueError(\n",
    "                    \"Attempting to fit with a non-positive \"\n",
    "                    \"weighted number of samples.\")\n",
    "\n",
    "        if minority_target is None:\n",
    "            # Determine the minority class label.\n",
    "            stats_c_ = Counter(y)\n",
    "            maj_c_ = max(stats_c_, key=stats_c_.get)\n",
    "            min_c_ = min(stats_c_, key=stats_c_.get)\n",
    "            self.minority_target = min_c_\n",
    "        else:\n",
    "            self.minority_target = minority_target\n",
    "\n",
    "        # Check parameters.\n",
    "        self._validate_estimator()\n",
    "\n",
    "        # Clear any previous fit results.\n",
    "        self.estimators_ = []\n",
    "        self.estimator_weights_ = np.zeros(self.n_estimators, dtype=np.float64)\n",
    "        self.estimator_errors_ = np.ones(self.n_estimators, dtype=np.float64)\n",
    "\n",
    "        random_state = check_random_state(self.random_state)\n",
    "\n",
    "        for iboost in range(self.n_estimators):\n",
    "            X_min = X[np.where(y == self.minority_target)]\n",
    "\n",
    "            # SMOTE step.\n",
    "            if len(X_min) >= self.smote.k:\n",
    "                self.smote.fit(X_min)\n",
    "                X_syn = self.smote.sample(self.n_samples)\n",
    "                y_syn = np.full(X_syn.shape[0], fill_value=self.minority_target,\n",
    "                                dtype=np.int64)\n",
    "\n",
    "                # Normalize synthetic sample weights based on current training set.\n",
    "                sample_weight_syn = np.empty(X_syn.shape[0], dtype=np.float64)\n",
    "                sample_weight_syn[:] = 1. / X.shape[0]\n",
    "\n",
    "                # Combine the original and synthetic samples.\n",
    "                X = np.vstack((X, X_syn))\n",
    "                y = np.append(y, y_syn)\n",
    "\n",
    "                # Combine the weights.\n",
    "                sample_weight = \\\n",
    "                    np.append(sample_weight, sample_weight_syn).reshape(-1, 1)\n",
    "                sample_weight = \\\n",
    "                    np.squeeze(normalize(sample_weight, axis=0, norm='l1'))\n",
    "\n",
    "                # X, y, sample_weight = shuffle(X, y, sample_weight,\n",
    "                #                              random_state=random_state)\n",
    "\n",
    "            # Boosting step.\n",
    "            sample_weight, estimator_weight, estimator_error = self._boost(\n",
    "                iboost,\n",
    "                X, y,\n",
    "                sample_weight,\n",
    "                random_state)\n",
    "\n",
    "            # Early termination.\n",
    "            if sample_weight is None:\n",
    "                break\n",
    "\n",
    "            self.estimator_weights_[iboost] = estimator_weight\n",
    "            self.estimator_errors_[iboost] = estimator_error\n",
    "\n",
    "            # Stop if error is zero.\n",
    "            if estimator_error == 0:\n",
    "                break\n",
    "\n",
    "            sample_weight_sum = np.sum(sample_weight)\n",
    "\n",
    "            # Stop if the sum of sample weights has become non-positive.\n",
    "            if sample_weight_sum <= 0:\n",
    "                break\n",
    "\n",
    "            if iboost < self.n_estimators - 1:\n",
    "                # Normalize.\n",
    "                sample_weight /= sample_weight_sum\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.474298Z",
     "iopub.status.busy": "2021-11-18T18:25:58.473527Z",
     "iopub.status.idle": "2021-11-18T18:25:58.515005Z",
     "shell.execute_reply": "2021-11-18T18:25:58.514319Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.474249Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger('pycobra.classifiercobra')\n",
    "\n",
    "\n",
    "class ClassifierCobra(BaseEstimator):\n",
    "    \"\"\"\n",
    "    Classification algorithm as introduced by\n",
    "    Mojirsheibani [1999] Combining Classifiers via Discretization,\n",
    "    Journal of the American Statistical Association.\n",
    "    Parameters\n",
    "    ----------\n",
    "    random_state: integer or a numpy.random.RandomState object.\n",
    "        Set the state of the random number generator to pass on to shuffle and loading machines, to ensure\n",
    "        reproducibility of your experiments, for example.\n",
    "    Attributes\n",
    "    ----------\n",
    "    machines: A dictionary which maps machine names to the machine objects.\n",
    "            The machine object must have a predict method for it to be used during aggregation.\n",
    "    machine_predictions: A dictionary which maps machine name to it's predictions over X_l\n",
    "            This value is used to determine which points from y_l are used to aggregate.\n",
    "    \"\"\"\n",
    "    def __init__(self, random_state=None, machine_list='basic'):\n",
    "        self.random_state = random_state\n",
    "        self.machine_list = machine_list\n",
    "\n",
    "    def fit(self, X, y, default=True, X_k=None, X_l=None, y_k=None, y_l=None):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_samples, n_features]\n",
    "            Training data which will be used to create ClassifierCobra.\n",
    "        y: array-like [n_samples]\n",
    "            Training labels for classification.\n",
    "        default: bool, optional\n",
    "            If set as true then sets up COBRA with default machines and splitting.\n",
    "        X_k : shape = [n_samples, n_features]\n",
    "            Training data which is used to train the machines loaded into COBRA.\n",
    "        y_k : array-like, shape = [n_samples]\n",
    "            Target values used to train the machines loaded into COBRA.\n",
    "        X_l : shape = [n_samples, n_features]\n",
    "            Training data which is used during the aggregation of COBRA.\n",
    "        y_l : array-like, shape = [n_samples]\n",
    "            Target values which are actually used in the aggregation of COBRA.\n",
    "        \"\"\"\n",
    "\n",
    "        X, y = check_X_y(X, y)\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.X_k_ = X_k\n",
    "        self.X_l_ = X_l\n",
    "        self.y_k_ = y_k\n",
    "        self.y_l_ = y_l\n",
    "        self.estimators_ = {}\n",
    "\n",
    "        # try block to pass scikit-learn estimator check.\n",
    "        try:\n",
    "            # set-up COBRA with default machines\n",
    "            if default:\n",
    "                self.split_data()\n",
    "                self.load_default(machine_list=self.machine_list)\n",
    "                self.load_machine_predictions()\n",
    "        except ValueError:\n",
    "            return self\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def pred(self, X, M, info=False):\n",
    "        \"\"\"\n",
    "        Performs the CLassififerCobra aggregation scheme, used in predict method.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        M: int, optional\n",
    "            M refers to the number of machines the prediction must be close to to be considered during aggregation.\n",
    "        info: boolean, optional\n",
    "            If info is true the list of points selected in the aggregation is returned.\n",
    "        Returns\n",
    "        -------\n",
    "        result: prediction\n",
    "        \"\"\"\n",
    "\n",
    "        # dictionary mapping machine to points selected\n",
    "        select = {}\n",
    "        for machine in self.estimators_:\n",
    "            # machine prediction\n",
    "            label = self.estimators_[machine].predict(X)\n",
    "            select[machine] = set()\n",
    "            # iterating from l to n\n",
    "            # replace with numpy iteration\n",
    "            for count in range(0, len(self.X_l_)):\n",
    "                if self.machine_predictions_[machine][count] == label:\n",
    "                    select[machine].add(count)\n",
    "\n",
    "        points = []\n",
    "        # count is the indice number.\n",
    "        for count in range(0, len(self.X_l_)):\n",
    "            # row check is number of machines which picked up a particular point\n",
    "            row_check = 0\n",
    "            for machine in select:\n",
    "                if count in select[machine]:\n",
    "                    row_check += 1\n",
    "            if row_check == M:\n",
    "                points.append(count)\n",
    "\n",
    "        # if no points are selected, return 0\n",
    "        if len(points) == 0:\n",
    "            if info:\n",
    "                logger.info(\"No points were selected, prediction is 0\")\n",
    "                return (0, 0)\n",
    "            logger.info(\"No points were selected, prediction is 0\")\n",
    "            return 0\n",
    "\n",
    "        # aggregate\n",
    "        classes = {}\n",
    "        for label in np.unique(self.y_l_):\n",
    "            classes[label] = 0\n",
    "\n",
    "        for point in points:\n",
    "            classes[self.y_l_[point]] += 1\n",
    "\n",
    "        result = int(max(classes, key=classes.get))\n",
    "        if info:\n",
    "            return result, points\n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict(self, X, M=None, info=False):\n",
    "        \"\"\"\n",
    "        Performs the ClassifierCobra aggregation scheme, calls pred.\n",
    "        ClassifierCobra performs a majority vote among all points which are retained by the COBRA procedure.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        M: int, optional\n",
    "            M refers to the number of machines the prediction must be close to to be considered during aggregation.\n",
    "        info: boolean, optional\n",
    "            If info is true the list of points selected in the aggregation is returned.\n",
    "        Returns\n",
    "        -------\n",
    "        result: prediction\n",
    "        \"\"\"\n",
    "        X = check_array(X)\n",
    "\n",
    "        if M is None:\n",
    "            M = len(self.estimators_)\n",
    "        if X.ndim == 1:\n",
    "            return self.pred(X.reshape(1, -1), M=M)\n",
    "\n",
    "        result = np.zeros(len(X))\n",
    "        avg_points = 0\n",
    "        index = 0\n",
    "        for vector in X:\n",
    "            if info:\n",
    "                result[index], points = self.pred(vector.reshape(1, -1), M=M, info=info)\n",
    "                avg_points += len(points)\n",
    "            else:\n",
    "                result[index] = self.pred(vector.reshape(1, -1), M=M)\n",
    "            index += 1\n",
    "        \n",
    "        if info:\n",
    "            avg_points = avg_points / len(X_array)\n",
    "            return result, avg_points\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "    def predict_proba(self, X, kernel=None, metric=None, bandwidth=1, **kwargs): \n",
    "        \"\"\"\n",
    "        Performs the ClassifierCobra aggregation scheme and calculates probability of a point being in a particular class.\n",
    "        ClassifierCobra performs a majority vote among all points which are retained by the COBRA procedure.\n",
    "        \n",
    "        NOTE: this method is to visualise boundaries.\n",
    "        The current method is just the mean of the consituent machines, as the concept of that kind of predicted probability\n",
    "        doesn't exist (yet) for classifier cobra.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: array-like, [n_features]\n",
    "        \"\"\"\n",
    "\n",
    "        probs = []\n",
    "        for machine in self.estimators_:\n",
    "            try:\n",
    "                probs.append(self.estimators_[machine].predict_proba(X))\n",
    "            except AttributeError:\n",
    "                continue\n",
    "        prob = np.mean(probs, axis=0)\n",
    "        return prob\n",
    "\n",
    "\n",
    "    def split_data(self, k=None, l=None, shuffle_data=True):\n",
    "        \"\"\"\n",
    "        Split the data into different parts for training machines and for aggregation.\n",
    "        Parameters\n",
    "        ----------\n",
    "        k : int, optional\n",
    "            k is the number of points used to train the machines.\n",
    "            Those are the first k points of the data provided.\n",
    "        l: int, optional\n",
    "            l is the number of points used to form the ClassifierCobra aggregate.\n",
    "        shuffle: bool, optional\n",
    "            Boolean value to decide to shuffle the data before splitting.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        if shuffle_data:\n",
    "            self.X_, self.y_ = shuffle(self.X_, self.y_, random_state=self.random_state)\n",
    "\n",
    "        if k is None and l is None:\n",
    "            k = int(len(self.X_) / 2)\n",
    "            l = int(len(self.X_))\n",
    "\n",
    "        if k is not None and l is None:\n",
    "            l = len(self.X_) - k\n",
    "\n",
    "        if l is not None and k is None:\n",
    "            k = len(self.X_) - l\n",
    "\n",
    "        self.X_k_ = self.X_[:k]\n",
    "        self.X_l_ = self.X_[k:l]\n",
    "        self.y_k_ = self.y_[:k]\n",
    "        self.y_l_ = self.y_[k:l]\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_default(self, machine_list='basic'):\n",
    "        \"\"\"\n",
    "        Loads 4 different scikit-learn regressors by default. The advanced list adds more machines. \n",
    "        As of current release SGD algorithm is not included in the advanced list.\n",
    "        Parameters\n",
    "        ----------\n",
    "        machine_list: optional, list of strings\n",
    "            List of default machine names to be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        if machine_list == 'cobra':\n",
    "            machine_list = ['cobra', 'cobra', 'cobra', 'cobra', 'cobra', 'cobra']\n",
    "\n",
    "        for machine in machine_list:\n",
    "            try:\n",
    "                if machine == 'svm':\n",
    "                    self.estimators_['svm'] = svm.SVC().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'knn':\n",
    "                    self.estimators_['knn'] = neighbors.KNeighborsClassifier().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'tree':\n",
    "                    self.estimators_['tree'] = tree.DecisionTreeClassifier().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'logreg':\n",
    "                    self.estimators_['logreg'] = LogisticRegression(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'naive_bayes':\n",
    "                    self.estimators_['naive_bayes'] = GaussianNB().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'lda':\n",
    "                    self.estimators_['lda'] = LinearDiscriminantAnalysis().fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'neural_network':\n",
    "                    self.estimators_['neural_network'] = MLPClassifier(random_state=self.random_state).fit(self.X_k_, self.y_k_)\n",
    "                if machine == 'cobra':\n",
    "                    self.estimators_['cobra'] = SMOTEBoost().fit(self.X_k_, self.y_k_)\n",
    "            except ValueError:\n",
    "                continue\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine(self, machine_name, machine):\n",
    "        \"\"\"\n",
    "        Adds a machine to be used during the aggregation strategy.\n",
    "        The machine object must have been trained using X_k and y_k, and must have a 'predict()' method.\n",
    "        After the machine is loaded, for it to be used during aggregation, load_machine_predictions must be run.\n",
    "        Parameters\n",
    "        ----------\n",
    "        machine_name : string\n",
    "            Name of the machine you are loading\n",
    "        machine: machine/regressor object\n",
    "            The regressor machine object which is mapped to the machine_name\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "\n",
    "        self.estimators_[machine_name] = machine\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine_predictions(self, predictions=None):\n",
    "        \"\"\"\n",
    "        Stores the trained machines' predicitons on D_l in a dictionary, to be used for predictions.\n",
    "        Should be run after all the machines to be used for aggregation is loaded.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions: dictionary, optional\n",
    "            A pre-existing machine:predictions dictionary can also be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        self.machine_predictions_ = {}\n",
    "        if predictions is None:\n",
    "            for machine in self.estimators_:\n",
    "                self.machine_predictions_[machine] = self.estimators_[machine].predict(self.X_l_)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    def load_machine_proba_predictions(self, predictions=None):\n",
    "        \"\"\"\n",
    "        Stores the trained machines' predicitons on D_l in a dictionary, to be used for predictions.\n",
    "        Should be run after all the machines to be used for aggregation is loaded.\n",
    "        Parameters\n",
    "        ----------\n",
    "        predictions: dictionary, optional\n",
    "            A pre-existing machine:predictions dictionary can also be loaded.\n",
    "        Returns\n",
    "        -------\n",
    "        self : returns an instance of self.\n",
    "        \"\"\"\n",
    "        self.machine_proba_predictions_ = {}\n",
    "        if predictions is None:\n",
    "            for machine in self.estimators_:\n",
    "                try:\n",
    "                    self.machine_proba_predictions_[machine] = self.estimators_[machine].predict_proba(self.X_l_)\n",
    "                except AttributeError:\n",
    "                    self.machine_proba_predictions_[machine] = self.estimators_[machine].decision_function(self.X_l_)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:25:58.773066Z",
     "iopub.status.busy": "2021-11-18T18:25:58.772676Z",
     "iopub.status.idle": "2021-11-18T18:26:07.733253Z",
     "shell.execute_reply": "2021-11-18T18:26:07.732122Z",
     "shell.execute_reply.started": "2021-11-18T18:25:58.773035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycobra in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.2.5)\n",
      "Requirement already satisfied: pandas in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pycobra) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pycobra) (0.23.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pycobra) (1.5.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pycobra) (1.18.5)\n",
      "Requirement already satisfied: seaborn in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pycobra) (0.10.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pycobra) (3.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->pycobra) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from pandas->pycobra) (2020.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->pycobra) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from scikit-learn->pycobra) (2.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->pycobra) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->pycobra) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from matplotlib->pycobra) (1.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas->pycobra) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# from pycobra.classifiercobra import ClassifierCobra\n",
    "%pip install pycobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.742436Z",
     "iopub.status.busy": "2021-11-18T18:26:07.740719Z",
     "iopub.status.idle": "2021-11-18T18:26:07.750399Z",
     "shell.execute_reply": "2021-11-18T18:26:07.749211Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.742389Z"
    }
   },
   "outputs": [],
   "source": [
    "# from pycobra.classifiercobra import ClassifierCobra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.752542Z",
     "iopub.status.busy": "2021-11-18T18:26:07.752223Z",
     "iopub.status.idle": "2021-11-18T18:26:07.763134Z",
     "shell.execute_reply": "2021-11-18T18:26:07.762019Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.752501Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils.estimator_checks import check_estimator\n",
    "# check_estimator(ClassifierCobra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.767124Z",
     "iopub.status.busy": "2021-11-18T18:26:07.766752Z",
     "iopub.status.idle": "2021-11-18T18:26:07.882884Z",
     "shell.execute_reply": "2021-11-18T18:26:07.882190Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.767087Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data[:-20]\n",
    "y = bc.target[:-20]\n",
    "X_test = bc.data[-20:]\n",
    "y_test = bc.target[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.884602Z",
     "iopub.status.busy": "2021-11-18T18:26:07.884167Z",
     "iopub.status.idle": "2021-11-18T18:26:07.888559Z",
     "shell.execute_reply": "2021-11-18T18:26:07.887586Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.884566Z"
    }
   },
   "outputs": [],
   "source": [
    "cc = ClassifierCobra(machine_list='basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:07.890539Z",
     "iopub.status.busy": "2021-11-18T18:26:07.889963Z",
     "iopub.status.idle": "2021-11-18T18:26:08.038051Z",
     "shell.execute_reply": "2021-11-18T18:26:08.037271Z",
     "shell.execute_reply.started": "2021-11-18T18:26:07.890504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "cc.fit(X, y)\n",
    "f1_score(y_test, cc.predict(X_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:08.039711Z",
     "iopub.status.busy": "2021-11-18T18:26:08.039295Z",
     "iopub.status.idle": "2021-11-18T18:26:11.335207Z",
     "shell.execute_reply": "2021-11-18T18:26:11.334305Z",
     "shell.execute_reply.started": "2021-11-18T18:26:08.039676Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/creditcard.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.337009Z",
     "iopub.status.busy": "2021-11-18T18:26:11.336685Z",
     "iopub.status.idle": "2021-11-18T18:26:11.379326Z",
     "shell.execute_reply": "2021-11-18T18:26:11.378581Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.336968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.382118Z",
     "iopub.status.busy": "2021-11-18T18:26:11.381580Z",
     "iopub.status.idle": "2021-11-18T18:26:11.391612Z",
     "shell.execute_reply": "2021-11-18T18:26:11.390711Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.382078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.393876Z",
     "iopub.status.busy": "2021-11-18T18:26:11.393265Z",
     "iopub.status.idle": "2021-11-18T18:26:11.761794Z",
     "shell.execute_reply": "2021-11-18T18:26:11.760991Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.393839Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>3.919560e-15</td>\n",
       "      <td>5.688174e-16</td>\n",
       "      <td>-8.769071e-15</td>\n",
       "      <td>2.782312e-15</td>\n",
       "      <td>-1.552563e-15</td>\n",
       "      <td>2.010663e-15</td>\n",
       "      <td>-1.694249e-15</td>\n",
       "      <td>-1.927028e-16</td>\n",
       "      <td>-3.137024e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.537294e-16</td>\n",
       "      <td>7.959909e-16</td>\n",
       "      <td>5.367590e-16</td>\n",
       "      <td>4.458112e-15</td>\n",
       "      <td>1.453003e-15</td>\n",
       "      <td>1.699104e-15</td>\n",
       "      <td>-3.660161e-16</td>\n",
       "      <td>-1.206049e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  3.919560e-15  5.688174e-16 -8.769071e-15  2.782312e-15   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean  -1.552563e-15  2.010663e-15 -1.694249e-15 -1.927028e-16 -3.137024e-15   \n",
       "std    1.380247e+00  1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00   \n",
       "min   -1.137433e+02 -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01   \n",
       "25%   -6.915971e-01 -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01   \n",
       "50%   -5.433583e-02 -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02   \n",
       "75%    6.119264e-01  3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01   \n",
       "max    3.480167e+01  7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   ...  1.537294e-16  7.959909e-16  5.367590e-16  4.458112e-15   \n",
       "std    ...  7.345240e-01  7.257016e-01  6.244603e-01  6.056471e-01   \n",
       "min    ... -3.483038e+01 -1.093314e+01 -4.480774e+01 -2.836627e+00   \n",
       "25%    ... -2.283949e-01 -5.423504e-01 -1.618463e-01 -3.545861e-01   \n",
       "50%    ... -2.945017e-02  6.781943e-03 -1.119293e-02  4.097606e-02   \n",
       "75%    ...  1.863772e-01  5.285536e-01  1.476421e-01  4.395266e-01   \n",
       "max    ...  2.720284e+01  1.050309e+01  2.252841e+01  4.584549e+00   \n",
       "\n",
       "                V25           V26           V27           V28         Amount  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  284807.000000   \n",
       "mean   1.453003e-15  1.699104e-15 -3.660161e-16 -1.206049e-16      88.349619   \n",
       "std    5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01     250.120109   \n",
       "min   -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01       0.000000   \n",
       "25%   -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02       5.600000   \n",
       "50%    1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02      22.000000   \n",
       "75%    3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02      77.165000   \n",
       "max    7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   25691.160000   \n",
       "\n",
       "               Class  \n",
       "count  284807.000000  \n",
       "mean        0.001727  \n",
       "std         0.041527  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.764020Z",
     "iopub.status.busy": "2021-11-18T18:26:11.763477Z",
     "iopub.status.idle": "2021-11-18T18:26:11.791112Z",
     "shell.execute_reply": "2021-11-18T18:26:11.790308Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.763975Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.792931Z",
     "iopub.status.busy": "2021-11-18T18:26:11.792606Z",
     "iopub.status.idle": "2021-11-18T18:26:11.802921Z",
     "shell.execute_reply": "2021-11-18T18:26:11.802209Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.792888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Frauds 99.83 % of the dataset\n",
      "Frauds 0.17 % of the dataset\n"
     ]
    }
   ],
   "source": [
    "print('No Frauds', round(df['Class'].value_counts()[0]/len(df) * 100,2), '% of the dataset')\n",
    "print('Frauds', round(df['Class'].value_counts()[1]/len(df) * 100,2), '% of the dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:11.805144Z",
     "iopub.status.busy": "2021-11-18T18:26:11.804625Z",
     "iopub.status.idle": "2021-11-18T18:26:12.004831Z",
     "shell.execute_reply": "2021-11-18T18:26:12.004167Z",
     "shell.execute_reply.started": "2021-11-18T18:26:11.805106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot('Class', data=df)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:12.007388Z",
     "iopub.status.busy": "2021-11-18T18:26:12.007095Z",
     "iopub.status.idle": "2021-11-18T18:26:15.572844Z",
     "shell.execute_reply": "2021-11-18T18:26:15.572172Z",
     "shell.execute_reply.started": "2021-11-18T18:26:12.007351Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABCsAAAEJCAYAAAC9l63LAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZwU5bX/8c9hR0FRAUUQGGBcUBYFccEFBRTcUKOJ+5IYQlyuvyxXzS96o1FvzHpvzFUJ+lNc4r4ii4hEloiIICAgooggIyAgiCyyzvP749RcmmaWmqGnq6fn+369+tXT1VVPne6pnqk6/TznsRACIiIiIiIiIiK5ok7SAYiIiIiIiIiIpFKyQkRERERERERyipIVIiIiIiIiIpJTlKwQERERERERkZyiZIWIiIiIiIiI5BQlK0REREREREQkpyhZITWSmU0ws/+phnbbm1kws57R4z7R4+aZ3lfUfrW8jqows8Fm9oWZFZvZnUnHkzQzW2xmv0w6DhERqfl03pJ5Om/ZVa6ct+TSMSI1n5IVkjPMbHj0DzaY2TYzW2lmb5vZDWZWP231C4FfxWz3TjObGzOMpUArYFYlQo8TwzVmtqGUp2K/jupkZvsBDwB/BFoDf0p7vk/K76as2zUJhL7Hyjk+jgUezGIc95vZDjP7cbb2mSmV/IyJiOQFnbckR+ct2T9viY6Jit7TPuTIMSL5oV7SAYikeQu4EqgLtABOB+4CrjSzviGEjQAhhDWZ3rGZNQghbAVWZLrtslTH66iidvjfg5EhhOWlPD8FPxkq8Z/A4fg/pBLrSn4wszqAhRB2VEOsWRFCWJWtfZlZQ+By4D7gOuDhbO1bRET2iM5bkqHzljRZOG95Dngj5fGTwBrg5pRla6JjUiQj1LNCcs2WEMKKEMKXIYRZIYS/AH2AY4BbSlZK72JmZhea2Ydm9p2ZrTGziWZ2YJQ1/w1wZHomPfr5BjN72cw2Av+Z3p0yxfFmNsvMNpvZDDPrkbLv3b59SO2GGWWZHwP2TonhzjJex35m9riZrY1ey1tmdmT6vsysr5nNNbON0bc4BeW9qWbW1sxeMbP10e1lM2tT0iYwM1p1URRf+9TtQwhbo9/LihDCCmATsDXl8QBglZmdFWX7twJHmNmxZvamma02s2/N7F9mdkJabMG8K+cL0etZZGZXpK3zH2a2xMy2mNkKM3si5bkBZjY5es/WmNlYMzsibfuDzewfZva1mW2KfpenVXB87NKdsrz3MHr+zuh3comZfRat86rF64p7IbAYuDd6345Ki7+k7aujuDaY2WNm1sDMrjezpdFr+0t0wlWyXazjKW1fu3QhruiYK+89FBGpBXTeovOWWnHeEkL4Lu093QLssiyEsLWUY2Rx9H4Mj/ax1Mx+YGbNzOzZ6Pj41MzOSHsPOpvZqGiblWb2jJkdVFpskr+UrJCcF0KYi2dyv1fa89EfrmeBx4EjgFPwbC94FvjPwAI8w94qWlbiN8BooAvenbAsfwJuBXoCi4BRZrZXzJcwBfg/+D/Kkhj+VMa6w4HjgEFAr2ibN8yscco6DfHudT8ETgCaAUPL2rmZGfAqcCD+jc9pwMHAq9Fzz+H/tIn22QrvVlpZjYDbgZ8AnYElQFP8d3Fy1PYsYHQp/wj/A3gN6BbF86iZtYvi/x7wS+B6oBA4B5iWsu3ewH9H7ffBvyl53cwaRNvvDUwE2gMX4L/r30bbVnR8ELVR0XtYoj3wg2g/ZwBH4wmIilwHPBVC2AS8HD1O1x4/Ls7BPwsX4+/ZsdG+rgNuivZdYjgVH09xlHfMxXoPRURqC5236LyF/D9vqaz/g78HxwDP48f+0/ix3B2YBDxlZo2i+FtFy+bi71M/oAkwwlK+lJFaIISgm245ccP/4Y0s47n7gE0pjycA/xP9fAwQgHZlbHsnMLeU5QH4W9qy9tHyntHjPtHjy1PWaQJ8A1wXPb4G2JDWTsl2zctap5TXURhtc0rK8/vi/8RS9xWAw1LWuRz/RqBOGa+/P7ADaJ+yrANQDPSLHveM2m1fWhultPk/wISUxyVx9ahgOwOWA1ek/R5+l/K4Hn6yc0X0+Of4P+X6MWPbO3q9J0WPfwysL/ldVOL4WAz8shLv4Z3AZmDflHV+DSysIN4O0e/voOjx6cBqoGFajN+ltf0isAposIfHU5xjt9xjrqz3UDfddNMtn2/ovEXnLaH2nbekrDsSGF7eMZIS1zNpx2MA7i/nOP4tMD6t3f2idXrF/YzqVvNvykxJTWH4H6jSzMbHjM41s5fM7Kdm1iJmu9NjrvduyQ8hhA3AHDwLn0lH4P9EUve1rpR9bQkhLEh5vAyoj39TUVa7y0IIi1PaXRRtl8nXsJ20Al9m1tLM/m5mn5jZOvyfb0ugbdq2H6bEth2/CG8ZLXoB//bjczP7f2Z2sXmNh5J9dDSzp6MujN8CX+G9xkr2cTTwYQhh9R68trjv4ZLod1ZiWcrrKMsP8X/IJWOOJ+AnPeenrfdFWttfAZ+EXceGfpWyv7jHUxyVPeZEpBRm9mjUnTkjBWnNi/LOim4jMtGmZIzOW3bSeUt+nbdURer7tQE/z5mT8vxX0X3JvnsAp0RDRDaYD1sq6T3TsRrikxylZIXUFJ3xboy7CV4M6Yzo9iHwI+BTM+sWo92NGYitGD8pSZVeBTyO9DZSpZ7wbC/jubI+z+WdMJW1vCq2hN0LUz2OD1P4GXAi3tWvCGiQtt62UuKqAxBCWAochnfT/Bbv/jgj6iYJ8Dpe1OwneFfUo/H3qGQf5b2vccV9D8t8HaU2alYX/3bnTDPbbmbb8W+b2rD7UJDS2i5vf3GOp7jHbmWPOREp3XB2dl/PhO9CCN2j23kZbFf2nM5bdtJ5S56ct+yBis5h0o+JOsAo/P1PvRXiPTqkltCJpuQ882KDA/Bu76UK7t0Qwl34P5ll+Bg88Iu/unsYxvEp8ewNHAXMjxatAvYys31S1u+etn2cGD7CP5P/W8gparNL9FxVfQS0tpTiU2bWAR+7uCftxnES3mV1VAhhHv4NRasKttlNCGFz1MbP8N/vkUBvMzsA//bgP0MIb4UQ5uPjTVNnOvoA6FpWwSji/26q4z0cAByAd2dN/Wd8DtA3dX9VEOd4inPsxpGJz5hI3gshTMKr5/+v6FvWN8yLIE42s8MTCk8yROctOm/J4/OWbPkAf8+WhBAWpt3WJx2cZI+SFZJrGprZQeZVkLuZ2c/xbvEzKKO4k5kdb2a3m1dwbgucBxzCzj/Gi4F2ZnaMeZXrhqW1U4Hbzay/eYXrR/F/FE9Hz72Hf9PxOzPrFBVWuj5t+8VAo6iN5qUVuQohfIoXa/q7mZ1sZl2Ap/Cs/NPp61fCW3iX03+YWQ/ziuH/wP8R/HMP2o3jE+AK84rOx+IFxSo1pZV5JfHrzKyLefXwa/Fs/KfAWry+w4+j9/5UvGhX6rc4TwMr8aJSJ5tZgZmdZ2anRc8vpuLjo7rew+uAMSGED0IIc1Nuo/Hxrj+sasMxj6c4x24ci9nzz5hIbTUMuCmE0AMvyvdgJbZtZGbTzWyqmaUPHZPs0HmLzlt2kefnLdnyAF7/5DkzO87MOphZPzMbZmZNkw5OskfJCsk1/fBCRl8A4/F/4HfhxZvK6vq4DuiNdwv7FO9ud3cI4ano+ZfwasPj8W8TLq1CXLdF7X5AVNk57Dp3+uV4MaM5wGDgjtSNQwhT8H9Gz0Qx3ELprsWrJY+I7vcCBoQQvqtCzCX7Dnj9g1X4CdTb+Jzs50fPVacf4oWUZuD/8B/F/8lWxjd4F9nJeFXo7wEXhhA+DyEU499EdY2eewB/77eUbBz9nk4FvsS7Xs7Dj6mS117h8VEd76GZHYj3oCjrm7cXgGttz6pel3s8xTl2Y8rEZ0yk1jGzJnhX8xfMbBbwd6Jvcc2ntpxbym1sShNtQwg9gcuA/zYzjeXOPp236LwlXV6et2RTCGEZ/hkpxmfWmYe/V1tIea8k/1kNOF5FRERE8kLULXtkCOGoqMv8ghBCpbuZl9Lu8KjdMoceiIiI1CTqWSEiIiKSgBDCt/iMARcDmItTZBEz26+k+3c0tr03NWMsuoiISCxKVoiIiIhkgZk9g0/zeJiZFZnZj/Du+D8ys9l4V+dBMZs7Apgebfc2cF8IQckKERHJGxoGIiIiIiIiIiI5RT0rRERERERERCSn1Kt4lZqtefPmoX379kmHISIiklNmzJixOoTQIuk4agudj4iIiOyuvPORvE9WtG/fnunTpycdhoiISE4xsyVJx1Cb6HxERERkd+Wdj2gYiIiIiIiIiIjkFCUrRERERERERCSnKFkhIiIiIiIiIjlFyQoRERERERERySlKVoiIiIiIiIhITlGyQkRERERERERyipIVIiIiIiIiIpJTlKwQERERERERkZyiZIWIiIiIiIiI5JR6SQdQ7VatgmHDyl9n8ODsxCIiIiIiIruo6FS9hE7ZRWoX9awQERERiZjZo2a20szmlvG8mdn9ZrbQzD40s2OyHaOIiEhtoGSFiIiIyE7DgQHlPD8QKIxug4GHshCTiIhIraNkhYiIiEgkhDAJWFPOKoOAJ4KbCjQzs1bZiU5ERKT2ULJCREREJL7WwNKUx0XRst2Y2WAzm25m01etWpWV4ERERPKFkhUiIiIi8Vkpy0JpK4YQhoUQeoYQerZo0aKawxIREckvSlaIiIiIxFcEHJLyuA2wLKFYRERE8paSFSIiIiLxjQCuimYFOR5YF0JYnnRQIiIi+aZe0gGIiIiI5AozewboAzQ3syLgN0B9gBDCUGA0cBawENgEXJtMpCIiIvlNyQoRERGRSAjh0gqeD8ANWQpHRESk1tIwEBERERERERHJKbGSFWY2wMwWmNlCM7utlOfNzO6Pnv/QzI6paFszu9jM5plZsZn1TFl+uZnNSrkVm1n36LkJUVslz7Xcs5cvIiIiIiIiIrmmwmSFmdUFHgAGAp2BS82sc9pqA4HC6DYYeCjGtnOBC4FJqQ2FEP4RQugeQugOXAksDiHMSlnl8pLnQwgrK/VqRURERERERCTnxelZ0QtYGEJYFELYCjwLDEpbZxDwRHBTgWZm1qq8bUMI80MICyrY96XAM5V4PSIiIiIiIiJSw8VJVrQGlqY8LoqWxVknzrbl+QG7Jysei4aA3GFmVom2RERERERERKQGiJOsKC0hEGKuE2fb0ndqdhywKYQwN2Xx5SGELsDJ0e3KMrYdbGbTzWz6qg0b4uxORERERERERHJEnGRFEXBIyuM2wLKY68TZtiyXkNarIoTwZXS/HngaH2aymxDCsBBCzxBCzxZNmsTcnYiIiIiIiIjkgjjJiveBQjMrMLMGeBJhRNo6I4CrollBjgfWhRCWx9x2N2ZWB7gYr3FRsqyemTWPfq4PnIMX6RQRERERERGRPFKvohVCCNvN7EZgLFAXeDSEMM/MhkTPDwVGA2cBC4FNwLXlbQtgZhcAfwNaAKPMbFYI4cxot6cARSGERSmhNATGRomKusBbwMN79OpFREREREREJOdUmKwACCGMxhMSqcuGpvwcgBvibhstfwV4pYxtJgDHpy3bCPSIE6+IiIiIiIiI1FxxhoGIiIiIiIiIiGSNkhUiIiIiIiIiklOUrBARERERERGRnKJkhYiIiIiIiIjkFCUrRERERERERCSnKFkhIiIiIiIiIjkl1tSlIiIiIiIimbRqFbz1FjzxBIQAZ50FLVokHZWI5AolK0REREREpFoMG7br4xBg0iSYPBmWLvVle+0FO3bAe+/B6ad70mKvvbIfq4jkFiUrRERERESk2m3c6L0oZs2CggIYNAiOOALatYP16+G117ynxZQpcOGFcNJJSUcsIklSskJERERERKrV55/Dww/DN9/AxRdD375gtvP5ffeFq66CPn3guefgySd9SMhhhyUWsogkTAU2RURERESkWoQA48fDH/7gj2+5Bfr12zVRkaptW7j5ZmjeHJ5+GrZvz16sIpJblKwQEREREZGM27HDe0k8/zx06QK33w7t21e8XYMGcMklsGIFjBtX7WGKSI5SskJERERERDLqu+/g+9+Ht9/2nhRDhlSuaGaXLtC9O4waBatXV1+cIpK7lKwQEREREZGM+fpr6N8fXnnF61NcfDHUqcJVxw9+4Ns991zmYxSR3KcCmyIiIiIikhELFsB558GSJZ5kWLu26m3tvz+cfTa8/LLPICIitYuSFSIiIiIisothwypeZ/DgXR+PHAmXXw4NG/oUpCedFK+d8vTrB1OneuLjL3+BRo32rD0RqTmUrBARERERkSoLAf7zP+GOO+Doo334R9u2mWm7bl343vfgb3+D11/3ISUi1W1Pk2yVkZ70k52UrBARERERkSpZs8Yvtl56CS67DB5+uHKFNOPo3BmaNYMnnlCyQnLH5s0+3Omzz+CLL2DTJti61W/btvnnYP/9d97atIGCAp/tRuJRskJERERERCptxAj4yU98to4//hF+8Qswy/x+6tSB446DMWNg5Upo2TLz+xCJY+NGePddeO89KCqC4mJf3rIl7LMPNG4M++4L9evDhg3w5ZcwZ44nL8B7CrVrB4WFnoQrLEzutdQEsZIVZjYA+CtQF3gkhHBf2vMWPX8WsAm4JoTwQXnbmtnFwJ3AEUCvEML0aHl7YD6wIGp+aghhSPRcD2A40BgYDdwcQgiVf9kiIiIiUltVpR6D7LRxIzz/vNeS6NoVRo/24R/V6fjjYexYeOYZuPnm6t2XSLrPP4eJE2H6dE88tG8PAwZAhw5+23vvsrcNAdav914Yn3wCCxfCuHF+PDdtCh9+6NP8nnKKJzNkpwqTFWZWF3gA6A8UAe+b2YgQwkcpqw0ECqPbccBDwHEVbDsXuBD4eym7/SyE0L2U5Q8Bg4GpeLJiADAmzgsVEREREZGqKy72BMUrr/i3xnfcAbffnp1u7QcfDD16+FAQJStqjpqeGPziC5+NZv58Lxx7wgmeVDjkkPhtmHmviy5d/AawZQvMnQszZvgxPXQotG4NP/4xXHed/5yqpr+PVRWnZ0UvYGEIYRGAmT0LDAJSkxWDgCeiXg5TzayZmbUC2pe1bQhhfrQsVqBRe/uEEN6NHj8BnI+SFSIiIpIhMXqT7gs8BbTFz6P+FEJ4LOuBSrWrrRcHZVmwAF54AZYu9W+Vb7oJfvvb7MZw1VWeqJg7F446Krv7luqTi5+11avhtddg2jTvNXHRRT67TePGmWm/YUNPvvXoAVdcAaNGwaOPwl13wd13+/S/118PfftWz9CqmqJOjHVaA0tTHhdFy+KsE2fb0hSY2Uwzm2hmJ6fsoyhOW2Y22Mymm9n0VRs2xNidiIiI1HYpPUIHAp2BS82sc9pqN+BfunQD+gB/NjOVS5O89eWX8OCDPm3oxo3wox/BrbdmbraPyrjkEqhXD558Mvv7ltph/Xo/vn/zG5g504d63HMP9O+fuURFur328sKxY8b4EJFf/hImT/Z99uzpQ65KamPUNnF6VpSWy0mvE1HWOnG2TbccaBtC+DqqUfGqmR1ZmbZCCMOAYQA927VTTQsRERGJI05v0gA0jep1NQHWANuzHahIdVuxAkaO9DH6DRvC+ef7t7xJzmTw6qtelHDYMJ9VoU4pX7vWpt4ukjnFxfDUU56oWLHCh3sMGgT77ZfdODp0gPvu8x4WTz0Ff/gD/OAHXsCzf3848URP2NUWcXpWFAGpo3LaAMtirhNn212EELaEEL6Ofp4BfAYcGrXVpjJtiYiIiFRCnB6h/4MXB18GzMGLfdfS77wkH338MVx5Jdx5pxf+O/NMuPdeGDgwN6ZcPP54+OYbj1MkE955x5MAV1/tM3W89x5cc032ExWpGjb0XkwffQQvvui9Ov7xD68RM3HiztlF8l2cvMz7QKGZFQBfApcAl6WtMwK4MfoG4jhgXQhhuZmtirHtLsysBbAmhLDDzDrgRTsXhRDWmNl6MzseeA+4Cvhb7FcqIiIiUr44vTjPBGYBpwMdgXFmNjmE8O1ujZkNxguD0zaJPvMSWwiweDHMmuWPmzXbeWvdOjsX6UmP258+HX73Oy+e2aiRf4t7xhk+W0Eu6drVu81Pneq9LCT/bdnin9FM12741788KTd+PBx4IAwf7om6OnV2/i1IWt268L3veQ2N+fPh9dfh6ad9yMiAAdC7t0+Tmq8qTFaEELab2Y3AWLzY1KMhhHlmNiR6fig+M8dZwEJ86tJry9sWwMwuwJMNLYBRZjYrhHAmcArwWzPbDuwAhoQQ1kTh/JSdU5eOQcU1RUREJHPi9Ai9FrgvKiq+0Mw+Bw4HpqU3tsuw1J49NSw1By1d6gX0ZsyAr7/eOawgdXx4o0ZeBO+EE6BTp/wqdldcDG++6fUoxo2DffeFX/8a/u3fPGmRi+rX93H8U6fC5s3++5H88e23Xq9hxQpYuRJWrfJaKf/+7z4UouTWtq1/HvfZZ9ftK0robdoEb70F99/vSYqWLeHPf4YhQzwJloQ4iUozT84dcYQnLUaO9Gl8S5IWJ51U/XEmIdaIlxDCaDwhkbpsaMrPAS84FWvbaPkrwG5/BkMILwEvldHWdEC1f0VERKQ6xOlN+gXQF5hsZgcChwGLshqllCvOiT/A22/Dc8/tvAg491zo1s0vfjds8KEGa9bA7Nne6+Cdd6BFC78oOPlknyGgplq7Fh57DB56yAv6HXQQ/P73fsGWfvGXi449FiZN8i7yxxyTdDSSCcXF/hl7+WX47jvYf3//vPXo4cMx1q/35MXSpV74siSh2Ly5Jy1at/bEw0cfed2HBg12fo7XrvWk5Ouve1Ju82bvSfGXv8BPfpJckqIqUpMWH3/sr+nZZ+GNN/w9+fGP8yuBV4vKc4iIiIiULWZv0ruB4WY2Bx82cmsIYXViQUulheAn+KNGeXLi6qt3Tzzss4/f2raF7t19FoqZM2HKFO9xMHq0j3Hv188vjGqC777zC5oXXvBCld99513I774bLrywakNd4iaGMq1jR78gmzdPyYp88OWXXo/hs8/g0EPhssugVauy19+2Db74AhYt8mTbRx95TxvwBFxJ76eQ1p+tfXu/mK9bFwoLvVDlU09Vy0uqdmaesDj8cE9ajBzpPaLuu8+LhP74x9U3e0k2KVkhIiIiEonRm3QZcEa245LMKC72byEnTvQL9csv9wuXijRs6IUdjz8eioq8G/mkSX7Bc+65cNVVcPbZvl6u2LHDu4tPmwZjx3pyZuNGOOAAH5f/0596IqYmqlvXL9I++qh6ahlI9syYAY884hfWV1/tw60q+n3Wr+8Jq44dvbYK+LG9ciV06QKffurHf7NmPrSpWTNPghx1lLedVJKtOqQmLQ491Gtw3Hyz15+59VYfFlOTeo6kU7JCRERERPLejh3w//6fXxydcYb3JqjKRW6bNj5TwPnne/fy4cPhtdf8guj73/dieEcf7V3Y4wrBu6avX+8XXdu2wfbtHvP2aGJcM+8RUqeO/1xyb+bbffWV3yZMgOXL/ZvnLVt826ZNvTv9Mcf4BU3dup7EmLZbpZWa48gjvQjiV1/5MBapeYqK/PNTUADXXw9NmlS9rb339nYuK3cqh/xlBqed5rcJEzxp8bOfwT33wE03wY03eqKyplGyQkRERETy3ltveaLiggu8IN2eatYMbrnFh1H885/w5JPepbzkW9tWrXzmii1bdk0wFBf7WPr163fer1+/MylRngcfLP95M79oa97cv6EuKPCu7y1b7iwemi9KZgKZN0/Jippo40YfstG4sdeN2JNEheyqTx9PWPzrX16L5s474Q9/8KEht9wCBx+ccICVoGSFiIiIiOS11au9V0K3bplJVKSqV897apxxhl98TZ0KH36487Zgwc5igCVDFvbe23s77LuvFwZs2tQv1kruGzTw3g/16u06TOX8872N4uKd98XFvs2BB3pvjkcfzezry1XNm+8sqNi3b9LRSGUUF/txunYt/OIX/jmQzDvpJL/NnQt//CM88IAnU089Fc48c8+Hh1TnVMollKwQERERkbwVAjz9tPcsuOSS6t1XkyZedLNfv53LMjk+vmfPzLWVDzp39hkktm3zOgZSM4wY4RfQl1/udSekeh11FDz+uPewuOMOL2Y6eTIMHOi9MHL5s5NnHcJERERERHaaMcOHCgwa5NMhSv448khPVCxcmHQkEtfcuTBmjBe4PfnkpKOpXQoKfKjar38N7drBiy/6MJHVOTyflZIVIiIiIpKXNm2C557zKUhPOy3paCTTSoqFfvRR0pFIHMXF8NJLPmTp0ks1i0tS2rb1GUOuvx6+/hruvRfmzEk6qtJpGIiIiIiI5KVXXvHilTfdlH8FJgUaNYJOnTxZ8b3vJR2NVGTGDFi2DK67rvqGHuTTtKSVVdnX3q0b/N//C0OHej2Ls86Cc87Jrb+VORSKiIiIiEhmLFkCkybB6af7N4mSnzp39ikw161LOhIpT3ExjBrls+T06JF0NFKiRQu49VY4/nj//Qwf7nV+coWSFSIiIiKSd8aN82/ezz036UikOpVMYaqhILlt+nRYvtw/j7n0zb347ENXX+29Kt57D8aOTTqinTQMRERERETyytq13uX8tNOgceOko8mc2tzFvSxt2viUr/PmwQknJB2NlKa4GEaO9Gl6jz466WikNGaerFixAl591X9XXbokHZV6VoiIiIhInpk40bsyq6hm/qtTx3tXzJ/vF8WSe6ZNg6++yr16CLIrM+9hccgh8Mgj3hMmaTpcRERERCRvbN3qtSq6dvXx2JL/OneGDRvgiy+SjkTS7djhtRDatIHu3ZOORirSoAH89KdeAPXBB2HjxmTj0TAQEREREckb77/vJ9h9+1b/vjQsIzcccYTff/JJsnHI7qZNg5Ur/QJYvSpqhv33hyFD4C9/gSee8N9dUnTIiIiIiEheCAH++U84+GA49NCko5Fs2XdfaNkSFi5MOhJJN2GCfx67dUs6EqmMTp182M6sWcl+rtSzQkRERERqhIp6MnzyiU9jeeWVPv5aao/CQpg50+tW6Bv83DBvHixeDBdfrM9jTdSvnyebXnoJbrklmd+hPsoiIiIikhfGj4e997tp0+gAACAASURBVIZevZKORLKtsBA2bdIUprlk+HBPHOnzWDM1aOBTzS5aBLNnJxNDrGSFmQ0wswVmttDMbivleTOz+6PnPzSzYyra1swuNrN5ZlZsZj1Tlvc3sxlmNie6Pz3luQlRW7OiW8uqv3QRERERyRerV/sJ9ckn+0m21C6dOvn9pEnJxiFu2zZ48kmf/nKffZKORqrqxBPhoIPglVe8WGq2VZisMLO6wAPAQKAzcKmZdU5bbSBQGN0GAw/F2HYucCGQ/idlNXBuCKELcDXwZNrzl4cQuke3lbFepYiIiIjktSlT/P7UU5ONQ5LRvDk0awaTJycdiQCMHevTlZ54YtKRyJ6oWxcuuABWrNj5Nzab4vSs6AUsDCEsCiFsBZ4FBqWtMwh4IripQDMza1XetiGE+SGEBek7CyHMDCEsix7OAxqZWcMqvToRERERyXshwIwZPhRg//2TjkaSYOa//0mT/HiQZD32mE8d3KVL0pHInurWDTp0gNdf96mhsylOsqI1sDTlcVG0LM46cbYtz/eAmSGELSnLHouGgNxhplItIiIiIrXdsmX+zV/PnhWvK/mrsNCPhUWLko6kdlu92i9sr7jCv5mXms0MLrwQ1q2Dt97K7r7jJCtKSwik5yvLWifOtqXv1OxI4PfAT1IWXx4NDzk5ul1ZxraDzWy6mU1ftWFDnN2JiIiISA01fbqfUB99dNKRSJJK6lZoKEiynn7aa1Zcc03SkUimFBZ6L5nx42H79uztN06yogg4JOVxG2BZzHXibLsbM2sDvAJcFUL4rGR5COHL6H498DQ+zGQ3IYRhIYSeIYSeLZo0qWh3IiIiIlJDlQwBOewwFfKr7Vq18mFAKrKZrOHD4ZhjoGvXpCORTOrTBzZsgA8/zN4+68VY532g0MwKgC+BS4DL0tYZAdxoZs8CxwHrQgjLzWxVjG13YWbNgFHAr0II76Qsrwc0CyGsNrP6wDlAljuiiIiIiEguKSryQn79+iUdiSStTh2fDUY9K7Jj2LDdly1dCjNnwiWXlP681FydO3sR2ylTPBmVDRX2rAghbAduBMYC84HnQwjzzGyImQ2JVhsNLAIWAg8D15e3LYCZXWBmRcAJwCgzGxu1dSPQCbgjbYrShsBYM/sQmIUnPx7e43dARERERGqsGTP8IlVDQAQ8WbFwISxfnnQktdO770K9enDssUlHIplWpw6ccALMnQvffJOdfcbpWUEIYTSekEhdNjTl5wDcEHfbaPkr+FCP9OX3APeUEUqPOPGKiIiISP5LHQLStGnS0UguOOUUv588Gb7//WRjqW2Ki/3zeOSRoJH4+emEE2DMGJg6NTv7i1OzQkREREQk5yxdCitXahYQ2enoo2HvvVW3IglLlvg37urllL8OPNAL2U6Zkp0pgpWsEBEREZEaqWQISPfuSUciuaJePTjxRNWtSMKsWf55VGHN/Na7t9cJmjKl+velZIWIiIiI1Dgh+JSlhx+uLueyq5NPhjlzYO3apCOpPULwwpqHHeY9WyR/HXMMNGwIjz5a/ftSskJEREREapwvvoDVqzUERHZ3yil+8fyvfyUdSe2xfLl/264hIPmvUSP/u/vccz6VaXVSskJEREREapwPPtAQECldr15Qvz68807SkdQeM2f6fbduycYh2dG7N2zcCC+8UL37UbJCRERERGqcuXO90Ju6nEu6xo29q7qSFdkzaxZ06ADNmiUdiWRDhw4+5Ke6h4IoWSEiIiIiNcratVBUBEcdlXQkkqt694b334ctW5KOJP+tXu3DstTLqfYwgyuu8KFWK1ZU336UrBARERGJmNkAM1tgZgvN7LYy1uljZrPMbJ6ZTcx2jALz5vl9ly7JxiG5q3dvT1R88EHSkeS/WbP8XvUqapdzzvH7MWOqbx9KVoiIiIgAZlYXeAAYCHQGLjWzzmnrNAMeBM4LIRwJXJz1QIU5c2C//aBVq6QjkVx14ol+r6Eg1W/mTGjdGlq2TDoSyaZu3eDgg2HUqOrbR73qa1pERESkRukFLAwhLAIws2eBQcBHKetcBrwcQvgCIISwMutR1nLbt8P8+XDccd4VWaQ0Bx3k4+qnTEk6kvz27bfw2Wdw9tlJRyLZ9vDD/hkbNQoeegjq1t19ncGD92wf6lkhIiIi4loDS1MeF0XLUh0K7GdmE8xshpldVVZjZjbYzKab2fRVq1ZVQ7i102efefd+1auQivTu7T0rQkg6kvw1e7a/v6pXUTt16QKbN8PChdXTvpIVIiIiIq607+nTL3PqAT2As4EzgTvM7NDSGgshDAsh9Awh9GzRokVmI63F5syBevW8Er1IeXr3hpUrPcEl1WPWLGjeHNq0SToSScLhh/vf4zlzqqd9DQMRERERcUXAISmP2wDLSllndQhhI7DRzCYB3YBPshOizJ0LhYXQqFHSkUguGjZs58/Lok/vvffCCSfsXL6nXdPFbdkCH38Mp56qIVm1VaNG/vd4zhy46KLMt6+eFSIiIiLufaDQzArMrAFwCTAibZ3XgJPNrJ6Z7QUcB8zPcpy11urVsHy5hoBIPK1aQePG1ddFvbb7+GOvIaNZeWq3Ll18+tLqGO2oZIWIiIgIEELYDtwIjMUTEM+HEOaZ2RAzGxKtMx94A/gQmAY8EkKYm1TMtU3JlKVKVkgcdep4AcBFi5KOJD/NmbPzm3WpvUr+HlfHUBANAxERERGJhBBGA6PTlg1Ne/xH4I/ZjEvc3Lk+Pv7AA5OORGqKjh1hxAjYuBH23jvpaPJHCH5x2rmz1yyQ2uvAA33a2jlz4PTTM9u2elaIiIiISM7bvNm7nR91lMbHS3ydOvm9eldk1uzZ8M036uUkrksX+OQTr2OSSUpWiIiIiEjOmzQJtm7VxZFUTvv2PhxEM4Jk1qhRfq96FQJ+HGzf7gnlTFKyQkRERERy3ujRUL++piyVymnYEA45RMmKTBs50hNB++yTdCSSCzp18s/a3AxXcIqVrDCzAWa2wMwWmtltpTxvZnZ/9PyHZnZMRdua2cVmNs/Mis2sZ1p7v4rWX2BmZ6Ys72Fmc6Ln7jdTJ0ARERGR2uDNN72QX4MGSUciNU3HjvD557BjR9KR5IdVq+C999TLSXaqXx+OOMLrVoSQuXYrTFaYWV3gAWAg0Bm41Mw6p602ECiMboOBh2JsOxe4EJiUtr/O+FRhRwIDgAejdojaHZyyrwGVeK0iIiIiUgMVFcH8+V7MT6SyOnaEbdtg6dKkI8kPY8b4BWnXrklHIrnkyCNh7VpYuTJzbcbpWdELWBhCWBRC2Ao8CwxKW2cQ8ERwU4FmZtaqvG1DCPNDCAtK2d8g4NkQwpYQwufAQqBX1N4+IYR3QwgBeAI4v/IvWURERERqknHj/P6II5KNQ2qmjh39fuHCZOPIF6NGwUEH+fAakRKHHur3n36auTbjJCtaA6l5yKJoWZx14mwbd3+to58rbMvMBpvZdDObvmrDhgp2JyIiIiK5bNw4nx6vdUVnkSKl2G8/OOAA1a3IhG3bYOxYOPtsL1wqUuLAA6Fp0+wnK0qrC5E+EqWsdeJsG3d/sdsKIQwLIfQMIfRs0aRJBbsTERERkVxVXOzJiv79NWWpVF2nTn4Rlcnx9LXRO+/AunWerBBJZeZ1hbKdrCgCUjv5tAGWxVwnzrZx91cU/VyZtkRERESkBps9G1av9mSFSFV16gTr12d2PH1tNGqUF7nt1y/pSCQXdeoEX38Na9Zkpr04yYr3gUIzKzCzBnjxyxFp64wAropmBTkeWBdCWB5z23QjgEvMrKGZFeCFNKdF7a03s+OjWUCuAl6L+0JFREREpOZ5802/V7JC9kRhod+rbsWeGTkSTj3Vu/uLpCv5nGWqd0WFyYoQwnbgRmAsMB94PoQwz8yGmNmQaLXRwCK8GObDwPXlbQtgZheYWRFwAjDKzMZG28wDngc+At4AbgghlEw09FPgkWg/nwFj9uzli4iIiEguGzfOp0hs1SrpSKQmO+ggaNIks13Ua5tFi+DjjzUERMrWpg00apS5z1m9OCuFEEbjCYnUZUNTfg7ADXG3jZa/ArxSxjb3AveWsnw6oBl9RURERGqBTZtg8mS48cakI5Gazsy7qKtnRdWNGuX355yTbBySu+rU2VkfJiPtZaYZEREREZHMmjwZtm7VEBDJjE6dYNUqWL486UhqppEj4bDDdk4FK1KawkJYsQK+/XbP21KyQkRERERy0ptvejG/U05JOhLJB506+f2//pVsHDXRhg0wYYJ6VUjFMlkfRskKEREREclJ48bBSSfBXnslHYnkg7ZtPfk1eXLSkdQ848d7LyfVq5CKtGsH9etnZiiIkhUiIiIiknOWL4c5c+CMM5KORPJF3brQoYOSFVUxciTss48nD0XKU6+ef86UrBARERGRvPTWW36vehWSSZ06wezZsG5d0pHUHCF4cc0zz/RvzEUqUlgIRUV7/jlTskJEREREcs6bb0Lz5tC9e9KRSD7p1Mkvvt99N+lIao6ZM72nk4aASFyFhf45mzJlz9pRskJEREREckoI3rOiXz+fCk8kUzp08G7qGgoS36hRPvXrwIFJRyI1RYcO/rd70qQ9a6deZsIREREREcmMuXN96jvVq5BMa9gQjjlGyYrKGDUKevWCli2TjkRqigYNvNDmCy9AQUHV21GuWkRERERyyptv+r3qVUh1OPlkmDYNtmxJOpLct3Klv1caAiKVVVgIixf7LDJVpWSFiIiIiOSUcePg8MOhTZukI5F8dNJJnqiYPj3pSHLfmDE+LOucc5KORGqaTp1gxw5YsqTqbShZISIiIiI5Y/NmmDhRQ0Ck+pRMv6mhIBUbORIOPliFbqXySoZ/fP551dtQskJEREREcsY773jCQkNApLo0bw6dO8OECUlHktu2bvUhWWed5QU2RSpjn33ggAOUrBARERGRPPHmm1C/PvTpk3Qkks9OP917VuzJePp8N3EifPstnHde0pFITVVQoGSFiIiIiOSJcePghBOgSZOkI5F81rcvbNoEU6cmHUnueu01aNzYpxAWqYqCAli7Ftatq9r2SlaIiIiISE5YuRJmzlS9Cql+ffpAnTowfnzSkeSmEGDECP8sNm6cdDRSU7Vv7/dV7V1RL2ORiIiIiIhU0bBhPkUiwIYN/likujRrBj16eLLirruSjib3zJoFS5fqvZE907atJwU//7xqRVqVrBARERGRnPDRR7DXXtCuXdKRSG3Qty/86U+eHNOwo139x394Uc01a5Q4lKpr0MCnoK5qzwoNAxERERGRxIUA8+fD4Yf7N3Ei1a1vX9i+HSZNSjqS3DN7NnToAE2bJh2J1HQFBbBkCRQXV37bWP8KzGyAmS0ws4Vmdlspz5uZ3R89/6GZHVPRtma2v5mNM7NPo/v9ouWXm9mslFuxmXWPnpsQtVXyXMvKv2QRERERyTXLl8M33/iUkiLZ0Ls3NGyouhXpvvjCh4B065Z0JJIPCgp8OuoVKyq/bYXJCjOrCzwADAQ6A5eaWfq/kYFAYXQbDDwUY9vbgPEhhEJgfPSYEMI/QgjdQwjdgSuBxSGEWSn7urzk+RDCysq/ZBERERHJNfPn+/0RRyQbh9QejRvDiScqWZFuxAi/r0qNAZF0BQV+X5WhIHF6VvQCFoYQFoUQtgLPAoPS1hkEPBHcVKCZmbWqYNtBwOPRz48D55ey70uBZyr1ikRERESqqKLepCnrHWtmO8zsomzGl88++ghatoTmzZOORGqTvn19yMOqVUlHkjteew0OPNBvInuqZUtPDFZXsqI1sDTlcVG0LM465W17YAhhOUB0X9qQjh+we7LisWgIyB1mZqUFbGaDzWy6mU1ftWFD2a9MREREJBKzN2nJer8HxmY3wvz13XewYIGGgEj29e3r92+/nWwcueKbb2DCBA0BkcypU8enMF28uArbxlintIRAiLlOnG1L36nZccCmEMLclMWXhxC6ACdHtytL2zaEMCyE0DOE0LOFSvuKiIhIPHF6kwLcBLwEaDhqhvzzn7BtG3TtmnQkUtv07An77KOhICXeeMOLjmoIiGRSQQF8+SVs3Vq57eIkK4qAQ1IetwGWxVynvG2/ioaKEN2n/8O/hLReFSGEL6P79cDT+EmFiIiISCZU2JvUzFoDFwBDK2psl56e6mNerpEjvdDhoYcmHYnUNvXqwamnKllR4rXXvNt+SZ0BkUxo395nA1mypHLb1YuxzvtAoZkVAF/iSYTL0tYZAdxoZs8CxwHrQgjLzWxVOduOAK4G7ovuXytpzMzqABcDp6Qsqwc0CyGsNrP6wDnAW5V7uSIiIiJlitMj9L+BW0MIO8oYjbpzwxCGAcMA2rXrGYYNK3/ngwfHjjOvhODJiiOOgPr1k45GaqO+feH11/1Cql27pKNJztatMHo0XHSRpg+WzEotsllYGH+7Cg/DEMJ24EZ8XOZ84PkQwjwzG2JmQ6LVRgOLgIXAw8D15W0bbXMf0N/MPgX6R49LnAIUhRAWpSxrCIw1sw+BWXjy4+H4L1VERESkXHF6k/YEnjWzxcBFwINmVlqRcIlp9mwoKtIQEElOSd2K2t67Yvx4+PZbOF9/0STD9tkHDjig8kU24/SsIIQwGk9IpC4bmvJzAG6Iu220/GugbxnbTACOT1u2EegRJ14RERGRKqiwN2kI4X87R5vZcGBkCOHVbAaZb0aO9PsuXZKNQ2qvI4/0mS/Gj4cf/jDpaJLzwgt+UXnGGfD44xWvL1IZBQXw2WeV20YdfERERESI3ZtUMmzkSOjVyy+SRJJgBmeeubO4ZG20bRu8+iqcd57XjxHJtIICWLsW1q2Lv42SFSIiIiKREMLoEMKhIYSOIYR7o2VDU3uUpqx7TQjhxexHmT+++gqmTYNzz006EqntBg2CNWvgX/9KOpJk/POffiF58cVJRyL5KrVuRVyxhoGIiIiIiGTa6NFeYPOcczxpIZINpRW73bzZZwa55x745JPaV/D2hRegaVMfAiJSHQ45xAu3fv55/Klx1bNCRERERBIxciS0aQPduiUdidR2jRr5jDSzZ3sCrTbZtg1eecWHgDRqlHQ0kq8aNPC/95XpWaFkhYiIiIhk3ZYt8Oab3quigllgRbKiWzdYvRqWpc8BlOfeftuHwGgIiFS3ggKfIri4ON76SlaIiIiISNZNnAgbNniyQiQXdO3qibNZs5KOJLtKhoCceWbSkUi+KyjwIVcrVsRbX8kKEREREcm6kSOhcWM4/fSkIxFx++4L7dvXrmRFyRCQc8/VEBCpfpUtsqkCmyIiIiKSVSHA669Dv36esBDJFd27+8V7UZGPr89HqQVGP/oIvv7aEzWlFR4VyaSWLf1v/uefQ+/eFa+vnhUiIiIiklXTpsHixXDhhUlHIrKrkmKvI0YkG0e2zJgBDRtC585JRyK1QZ063ntp8eKY61dnMCIiIiIi6Z55xi+QLrgg6UhEdnXQQf7t72uvJR1J9duxw4e8dO3qMzWIZENBAXz5JWzdWvG6SlaIiIiISNbs2AHPPQdnneVdz0VyiZn3rnj7bVi3LuloqteCBV7ktkePpCOR2qSgwGcDWbKk4nWVrBARERGRrJk40SvBX3pp0pGIlK57dy88+cYbSUdSvd59F/baC446KulIpDapTJFNJStEREREJGueeQaaNNGUpZK7OnSAFi3g1VeTjqT6fPcdzJwJxx4L9esnHY3UJk2bQvPmSlaIiIiISA7ZsgVeegnOP1+zgEjuqlPHj9HXX4f165OOpnp88IH3Hjn++KQjkdqofXslK0REREQkh4wdC2vXagiI5L4f/hA2boRnn006kuoxdSoceODOLvki2VRQ4P8LKqoLo2SFiIiIiGTFM8/AAQdA//5JRyJSvuOOgyOPhEceSTqSzFu9Gj75xHtVmCUdjdRGcetWKFkhIiIiItVu40YYMQIuukhj5CX3mcF118G0afDhh0lHk1nvvef3xx2XbBxSex1yiA+3UrJCRERERBI3YgRs2qQhIFJzXHklNGiQX70rQvAhIIcd5r2cRJLQoAG0aaNkhYiIiIjkgGeegdat4eSTk45EJJ4DDoALL4Qnn/TZM/LB1KmwcqUKa0ryCgpgyZLy14mVrDCzAWa2wMwWmtltpTxvZnZ/9PyHZnZMRdua2f5mNs7MPo3u94uWtzez78xsVnQbmrJNDzObE7V1v5lGWYmIiIjkuq++gjfegEsu8a6/IjXFddfBN9/Ayy8nHUlmPP64D8M65piK1xWpTgUFsHlz+etU+O/CzOoCDwADgc7ApWbWOW21gUBhdBsMPBRj29uA8SGEQmB89LjEZyGE7tFtSMryh6L2S/Y1oKL4RURERCRZw4b5NIk//nHSkYhUzmmnQYcO+TEUZPNmeO45OPpoaNQo6WiktoszE02c3HYvYGEIYVEIYSvwLDAobZ1BwBPBTQWamVmrCrYdBDwe/fw4cH55QUTt7RNCeDeEEIAnKtpGRERERJK1dSs89BAMGODj5EVqkjp14Ec/ggkT4NNPk45mz7z6qvcSOeGEpCMR8alz9967/HXiJCtaA0tTHhdFy+KsU962B4YQlgNE9y1T1isws5lmNtHMSkY2to62Ly8OAMxssJlNN7PpqzZsqOj1iYiIiEg1efFFWL4c/u3fko5EpGquuQbq1oVHH006kj3zt79Bx45w+OFJRyLiM+507Fj+OvXitFPKshBznTjbplsOtA0hfG1mPYBXzezIyrQVQhgGDAPo2a5dRfsTERERkWpy++3+DdqSJT4cRKSmOfhgOPtsT1bcfnvF3wbnog8+gClT4L/+S3VjJHd06lT+1MBxDtUi4JCUx22AZTHXKW/br6KhHSVDPFYChBC2hBC+jn6eAXwGHBq11aaCOEREREQkR7z3nk9Nd9ppukCSmu2WW3wWjfvvTzqSqvnb3zzJcu21SUcislNFPSvi/Nt4Hyg0swIzawBcAoxIW2cEcFU0K8jxwLpoaEd5244Aro5+vhp4DcDMWkSFOTGzDnghzUVRe+vN7PhoFpCrSrYRERERkdxz//1eyE9j5KWm690bzj0Xfv97WLMm6WgqZ9Uqnzr4qqtg332TjkZkp3btyn++wmRFCGE7cCMwFpgPPB9CmGdmQ8ysZKaO0cAiYCHwMHB9edtG29wH9DezT4H+0WOAU4APzWw28CIwJIRQ8ifhp8Aj0X4+A8ZUFL+IiIiIZN+yZfD8836Rp5kHJB/cey98+60nLGqShx+GLVvgxhuTjkRkV/Xrl/98nJoVhBBG4wmJ1GVDU34OwA1xt42Wfw30LWX5S8BLZbQ1HTgqTswiIiIikpy//x127PAhICL5oEsXuOIK7zF0003Qpk3F2yRt+3afjadfP+jcOeloRCpHowdFREREJKM2b4ahQ+Gcc6BFi6SjEcmc3/7Wk3C//W3SkcTz6qtQVKTZeKRmUrJCRERERDLq/vu9GOHPf550JCKZ1b49/PSnPjPIggVJR1Ox+++HggI466ykIxGpPCUrRERERCRjVq70sf3nnAN9+iQdjUjm/frXXofl9tuTjqR8s2bB5Mlwww1Qt27S0YhUXqyaFSIiIiJSPYqL/QL/3Xfhm2/8VreuX+zvtVfS0VXenXfCxo3wxz8mHYlI9WjZEn75S7jrLnjlFbjggqQjKt3dd0PTpvDDHyYdiUjVKFkhIiIikpANG7xS/8cfw29+s+tzTZp4cco+ffxngMGDsx5ipcyb54U1r78eDj886WhEqs+vfgWjR8O110K3btChQ9IR7WraNHj5ZU+o7Ldf0tGIVI2SFSIiIiIRMxsA/BWoCzwSQrgv7fnLgVujhxuAn4YQZldlX19+CQ8+6D0pLrwQWrf2nhR77QXr1sG4cfD66zB2rE//ee65e/LKsuPf/92/yU1PvIjkm4YNfWreo4+Giy+Gd97JnSl6Q4DbbvPitj/7WdLRiFSdkhUiIiIigJnVBR4A+gNFwPtmNiKE8FHKap8Dp4YQ1prZQGAYcFxl9/XBBzB8uF/c/OIXu38re9BBcNhhsGyZJy0mToQZM+DQQ+Hss6v4AqvZm2/CmDHwpz9B8+ZJRyNS/dq3h8cfh0GD/HP8wANJR+Teegvefhv++ldPHorUVCqwKSIiIuJ6AQtDCItCCFuBZ4FBqSuEEKaEENZGD6cCbSq7k7ff9qESBx/shfrK6z5+8MFw9dXe5bxpU69j8aMfec+LXLJjx86ky403Jh2NSPacd54f+w8+CM89l3Q0XgPnV7+Cdu3gJz9JOhqRPaOeFSIiIiKuNbA05XER5fea+BEwpqwnzWwwMBhg//3bAvDVV/Dii3DUUTBkCNSvHy+wtm39AmTZMrjvPu9t8dhj0LdvvO2r2913w9y5/toaNkw6GpE9N2xYxeuU1JD53e9gyhS47jrvbXFcpftaZc5LL3kvrMcf12dRaj71rBARERFxVsqyUOqKZqfhyYpbS3seIIQwLITQM4TQs0mTFhQXw5NPQoMGcNVV8RMVJerX9ylBp0yBxo2hXz/vxbBxY+XaybQxY+C3v4VrrvHaGyK1Tf36Xr+iZUv/XE6cmEwc27Z5b60jj4TLL08mBpFMUs8KEREREVcEHJLyuA2wLH0lM+sKPAIMDCF8HbfxyZPh0089UbHvvlUP8rjjYOZMvyj561/hjTe8/sVJJ/nzlflGeE8tXuwXRV27+nh9Ky3dI1ILtGnjn/F+/WDAAJ/SdMCA7MYwbJj/jXn1VZ/+WKSmU7JCRERExL0PFJpZAfAlcAlwWeoKZtYWeBm4MoTwSdyGd+zwaQQPPxxOPHHPA91rL/iv/4Lzz/epE085BX7+c7jnnj1vO67Nm+Gii3yM/IsvekwitdnBB3uvijPO8FoWzz0HF1yQnX3Pm+ez8RxxBKxYES9pKZLrlKwQERERAUII283sRmAsPnXpoyGEeWY2JHp+KPAfwAHAg+bdCLaHEHpWlbKANQAAEtdJREFU1PaaNZ6wuOKKzPY+OPVUmD3bL1L+/GcYPdoTGO3bZ24fZbn5Zh8b/+qr0KlT9e9PpCZo0cKL6A4c6FOaDhoE/ftDnXIG3+9pT6dNm+D73/civNdeqx5Okj9Us0JEREQkEkIYHUI4NITQMYRwb7RsaJSoIIRwXQhhvxBC9+hWYaIC4Lvv/KKlRYvMx9y0KQwd6sNBvv0Wfv97eO012L498/sCCAHuusu/ub3tNn9dIrJTs2ZeBPf8871H1YMPwoYN1be/m2+G+fPhqaf2bIiZSK5RskJERESkmjVoUP0zd5x5ps/I0auX97C46y6vbRFKLRFaNVu2+FSqd97ptTfuvjtzbYvkkyZN4IUX4JJLPJFwzz2wcGHm9/Pss/DII5447N8/8+2LJEnDQERERESqWbNm5XcDz+R+rr0Wjj3W60gMHepDNC66CAoK9qztNWt8to+JE332j9tvh4cfzkzcIjVRnLoQp50GHTv6un/+sycUzj47M9OKLlzoQ0hOPNE/kyL5RskKERERkWrWqFF293fUUV5o75134PXX4b77oFs3v3A6/PDKt/fee96TYvFi+Mc/4LLLKtxERCJt2/rsPS+8AGPHwvTp3uOia9eqt/nuu56ErFcPnnnG70XyjQ5rERERkTxUt67PEtKrl4+fnzjRi3G2auUzeFx2Wfnj24uLfTjJH/7gUzI2bw7jx++cIlVE4mvc2BN+J5zgCb8HHoDu3b23UmWE/9/evUdLVZ53HP/+4HC4WFGQoAjEW7ErRFcNWkVjvUaCLJW62jS6TCFegqmXVdskFRcrjV3LJJhoV2s0GpJCNZp4i8YTqyFBa/9oqmAU5aLoEVGPEhBrLJFGuTz9432PDIeZYeRcZvac32etd80+79575n2es2fOnvfs992RrtK4/HIYPx4efjh1hpg1o5o6KyRNBf6FNDP2DyJibpf1yuunAZuAz0fEU9X2lTQSuAs4EFgD/GVEvC3pNGAu0Aq8D3wlIh7N+zwGjAH+L7/0lIhYvzuBm5mZmRXN7tyOcMgQOPNMmDo1/Uf30Ufhkkvg0kvT1RfHHJPK/vvD+vWwbl0q99wDa9fCyJHprgbHHw8rV6ZiZrtnwoQ0hGrRInjwQVi6FJYsSbcePvHE6nfy+P3v0/t2/vx0t5E77oARI/qu7WZ9bZedFZIGAjcBpwEdwBJJbRFR+qfqdGBCLscANwPH7GLf2cAjETFX0uz885XABuDMiHhD0mGk24eNLXmt8yLiyW5FbWZmZtbPDBqU/qs7eXL6j+7ChWl4R1sbLFiw47bDh8M++8AFF8BRR6WrNMysZ7S0pM7D446Dxx5LQzpOPhkmTUp31/nYx1KZMCF1HC5atL28+Wbq7Lj6ar8vrfnVcmXF0UB7RKwGkHQnMB0o7ayYDtwWEQE8LmlvSWNIV01U2nc6cFLe/1bgMeDKiHi65HlXAEMkDY6I93YrQjMzMzP7gLT9agpIl5WvXg1vvQX77pvKkCG7dxWHmdVu+HA466x0FdPtt8N3vpM6ITrv4DNgQBqOBbDffumOPzNm+K4f1n/U0lkxFnit5OcO0tUTu9pm7C723Tci1gJExFpJo8u89p8DT3fpqFggaSvwE+Ca3EGyA0mzgFkAHx05snp0ZmZmZv2YlO5WcMgh9W6JWf80dCh84QupbNoEL7yQbnf6/PNpmMdpp8HEidWHiJg1o1o6K8q9Lbp2EFTappZ9y7+o9HHgWmBKSfV5EfG6pD1JnRV/Bdy20wtEzAPmARx1wAE9eHdxMzMzMzOz3jFsWBqmdcQR9W6JWf3VcsfvDmB8yc/jgDdq3KbavuvyUBHy4wcTZUoaB9wPzIiIlzrrI+L1/LgR+BFpiIqZmZmZmZmZNZFaOiuWABMkHSSpFTgHaOuyTRswQ8lk4J08xKPavm3AzLw8E3gAQNLewL8DV0XEf3W+gKQWSaPy8iDgDGD5h47YzMzMzMzMzBraLoeBRMQWSZeR7soxEJgfESskfTGvvwV4iHTb0nbSrUvPr7Zvfuq5wN2SLgReBT6T6y8D/hD4qqSv5ropwLvAwtxRMRBYBHy/O8GbmZmZmZmZWeOpZc4KIuIhUodEad0tJcsBXFrrvrn+LeDUMvXXANdUaMqRtbTXzMzMzCrznT7MGoffj2bl1TIMxMzMzMzMzMysz7izwszMzMzMzMwaijsrzMzMzMzMzKyhuLPCzMzMzMzMzBqKOyvMzMzMzMzMrKG4s8LMzMzMzMzMGoo7K8zMzMzMzMysobizwszMzMzMzMwaijsrzMzMzMzMzKyhuLPCzMzMzMzMzBqKOyvMzMzMzMzMrKG4s8LMzMzMzMzMGoo7K8zMzMzMzMysobTUuwF1EQFPPAGrV8OGDXD99bDPPtDWBqNG1bt1ZmZmZmZmZv1a/7yyYsUKWLAAFi+GjRvh8MPhqafg3HNh69Z6t87MzMzMzMysX+ufnRUPPwwjRsB118GcOXDvvfDd78KiRfC1r9W7dWZmZmZmZmb9Wv/rrHjxRWhvhylToKVkFMwFF8BFF8HXvw4/+1n92mdmZmZmZmbWz/W/OSseegj23BOOP3573bx56fGII+CjH4XPfhauuAIOOACktG7WrL5vq5mZmZmZmVk/1L86K9asgZUr4eyzobV15/WDBsHFF8M3vgHf/GaadPPww+Gww2DTJhg2rM+bbGZmZmZmZtbf1DQMRNJUSasktUuaXWa9JN2Q1z8radKu9pU0UtIvJb2YH0eUrLsqb79K0qdL6o+UtCyvu0HqvOyhRj//OQwdCieeWHmbUaPSvBXnnQfjxsGvfgU33pg6LqZNg5tugqVL4a230l1FzMzMrGl055zHzMzMes4ur6yQNBC4CTgN6ACWSGqLiJUlm50OTMjlGOBm4Jhd7DsbeCQi5uaTgdnAlZImAucAHwf2BxZJOjQitubnnQU8DjwETAUerhrAO+/AsmWpk+Lpp1OHw9Ch1YPeay844YRUNm9O81xAGkJy2WXbtxs6NHVojB6dOjlGjUoTd+6xRyrDhu342LVu8OA0zKS0DBhQuS79QnZ8LFfXU49mZtb3ImDbth0/+zvrN29OZdCgVDrXb9kC776bSmtr+jszZEhat3EjvPlmulV3Swt85COp2E66c87T1201MzNrdrUMAzkaaI+I1QCS7gSmA6V/uKcDt0VEAI9L2lvSGODAKvtOB07K+98KPAZcmevvjIj3gJcltQNHS1oDDI+I/87PdRvwZ9TSWXHjjWm5tRVOPbWGkEsMGgQTJ6bliRNh3Tro6IC334bf/jY9btgAr7wCv/tdOlHcvPnDvUaja6aOEV8NY0XXV8dwX75XGuF9WemzqNpnVKV1EdvLtm07/lxaIHUeDByYytatqdOh9BbagwalbbZtg/fe2/m1Bg9Oz/X++zuvGzAgPW+z/U3qXbt9zhMRa/u+uWZmZs2rls6KscBrJT93sPN/EMptM3YX++7b+Yc9ItZKGl3yXI+Xea7Neblr/U4kzSJdgQHwnmA5kE7mvvSlskFaFaVfJMp/qRgFbOij1vRHzm/vc457n3NczpYtqVTSeSVFJTt2YOyY423bUqnsgNoa2a9055xnp86KrucjF1+s5T3X1Lprxve0YyoGx1QMzRZTs8UDjRNTxfORWjoryv3rqOs31krb1LJvra9X83NFxDxgHoCkJyPiqF28pnWDc9y7nN/e5xz3Pue49znHPaI75zw7Vzbx+UizxQOOqSgcUzE0W0zNFg8UI6ZaJtjsAMaX/DwOeKPGbartuy4PFSE/rq/hucbtoh1mZmZmu6s75zxmZmbWg2rprFgCTJB0kKRW0uSXbV22aQNm5BmyJwPv5CEe1fZtA2bm5ZnAAyX150gaLOkg0gRWi/PzbZQ0Od8FZEbJPmZmZmbd1Z1zHjMzM+tBuxwGEhFbJF0GLAQGAvMjYoWkL+b1t5DuzDENaAc2AedX2zc/9VzgbkkXAq8Cn8n7rJB0N2kyqy3ApflOIAB/DfwbMJQ0sWb1yTWTeTVsY93jHPcu57f3Oce9zznufc5xN3XnnKcGzfb7abZ4wDEVhWMqhmaLqdnigQLEpGiEWdjNzMzMzMzMzLJahoGYmZmZmZmZmfUZd1aYmZmZmZmZWUNp2s4KSVMlrZLULml2vdtTNJLWSFomaamkJ3PdSEm/lPRifhxRsv1VOderJH26pP7I/Dztkm7Ik6P2S5LmS1ovaXlJXY/lNE9Ke1euf0LSgX0ZX71VyO/Vkl7Px/FSSdNK1jm/H5Kk8ZL+Q9JzklZI+ptc7+O4h1TJsY/lgmrk85Fmfk9LGijpaUkPNkNMkvaWdK+k5/Pv69gmiOlv83G3XNKPJQ0pWkyq47mdpJn5NV6U1HnTgt6K6dv52HtW0v2S9i5KTOXiKVn3ZUkhaVRR4qkWk6TLc7tXSPpWkWKqKCKarpAmxXoJOBhoBZ4BJta7XUUqwBpgVJe6bwGz8/Js4Nq8PDHneDBwUM79wLxuMXAs6b70DwOn1zu2Oub0BGASsLw3cgpcAtySl88B7qp3zA2Q36uBL5fZ1vndvRyPASbl5T2BF3IufRz3fo59LBew0ODnI838ngb+DvgR8GD+udAxAbcCF+XlVmDvIscEjAVeBobmn+8GPl+0mKjTuR0wElidH0fk5RG9GNMUoCUvX1ukmMrFk+vHkyZTfoX8nacI8VT5HZ0MLAIG559HFymmirH25pPXq+SkLyz5+Srgqnq3q0iF8p0Vq4AxeXkMsKpcfvMb/9i8zfMl9ecC36t3bHXO64FdPlh6LKed2+TlFmADeRLd/lLK5Pdqyn/Bc357Jt8PAKf5OO6THPtYLmChYOcjzfKeBsYBjwCnsL2zorAxAcNJX+zVpb7IMY0FXiN96WkBHiR9IS5cTNTh3I4u59TA94BzeyumLuvOBu4oUkzl4gHuBf6Yku88RYmnwnF3N/CpMtsVJqZypVmHgXR+AHbqyHVWuwB+IenXkmblun0j30s+P47O9ZXyPTYvd6237Xoypx/sExFbgHeAfXqt5cVxWb5scX7JpZjObzflSwI/ATyBj+Ne0SXH4GO5iApzPtJk7+l/Bv4e2FZSV+SYDgbeBBYoDW35gaQ9KHBMEfE6cB3wKrAWeCcifkGBYyrRFzHU87PlAtJ/4XdoX5d2NHRMks4CXo+IZ7qsKmQ82aHAn+ZhG/8p6U+6tq9LO4oQU9N2VpSbFyH6vBXF9smImAScDlwq6YQq21bKt38Pu293cup87+xm4BDgCNLJ0PW53vntBkl/APwEuCIi/rfapmXqnOcalMmxj+ViKkSum+k9LekMYH1E/LrWXcrUNVRMpP9sTgJujohPAO+ShhdU0vAx5Q7X6aTL0vcH9pD0uWq7lKlrqJhq0JMx1CU2SXOALcAdnVUV2tGwMUkaBswB/qHc6gptaNh4SrSQhmZMBr4C3J3noChyTE3bWdFBGofUaRzwRp3aUkgR8UZ+XA/cDxwNrJM0BiA/rs+bV8p3R17uWm/b9WROP9hHUguwF/A/vdbyAoiIdRGxNSK2Ad8nHcfg/O42SYNIX2ruiIj7crWP4x5ULsc+lgur4c9HmvA9/UngLElrgDuBUyTdTrFj6gA6IqLzKqt7SZ0XRY7pU8DLEfFmRGwG7gOOo9gxdeqLGPr8syVPpngGcF7kMQBV2tHIMR1C6iR7Jn9OjAOekrRflTY0cjydOoD7IllMurJsVJV2FCGmpu2sWAJMkHSQpFbSxCBtdW5TYUjaQ9KencukMYTLSTmcmTebSRrbSq4/J88cexAwAVicL33bKGly7tmbUbKPJT2Z09Ln+gvg0ZI/Jv1S58lCdjbpOAbnd7fknPwr8FxE/FPJKh/HPaRSjn0sF1ZDn48043s6Iq6KiHERcSAp349GxOcKHtNvgNck/VGuOhVYWeSYSMM/JksalttyKvBcwWPq1BcxLASmSBqRr1KZkut6haSpwJXAWRGxqWRV4WKKiGURMToiDsyfEx2kiYZ/U8R4SvyUNE8Pkg4lTcS7oeAxNecEm/lzaBppVuuXgDn1bk+RCmls5DO5rOjMH2ms0iPAi/lxZMk+c3KuV1Fyxw/gKNJJ9UvAjfTjSdyAH5Mu395M+mC8sCdzCgwB7gHaSbP7HlzvmBsgvz8ElgHPkj54xzi/3crx8aTL/Z4FluYyzcdxn+TYx3JBCw18PtLs72ngJLZPsFnomEhDwJ7Mv6ufki73LnpM/wg8n9vzQ9LdCgoVE3U8tyPNHdGey/m9HFM7aa6Czs+JW4oSU7l4uqxfQ8lNBRo9niq/o1bg9tzGp4BTihRTpdLZIDMzMzMzMzOzhtCsw0DMzMzMzMzMrKDcWWFmZmZmZmZmDcWdFWZmZmZmZmbWUNxZYWZmZmZmZmYNxZ0VZmZmZmZmZtZQ3FlhZmZmZmZmZg3FnRVmZmZmZmZm1lD+Hyhbd8Yqm933AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1296x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(18,4))\n",
    "\n",
    "amount_val = df['Amount'].values\n",
    "time_val = df['Time'].values\n",
    "\n",
    "sns.distplot(amount_val, ax=ax[0], color='r')\n",
    "ax[0].set_title('Distribution of Transaction Amount', fontsize=14)\n",
    "ax[0].set_xlim([min(amount_val), max(amount_val)])\n",
    "\n",
    "sns.distplot(time_val, ax=ax[1], color='b')\n",
    "ax[1].set_title('Distribution of Transaction Time', fontsize=14)\n",
    "ax[1].set_xlim([min(time_val), max(time_val)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:00.907967Z",
     "iopub.status.busy": "2021-11-18T18:30:00.907161Z",
     "iopub.status.idle": "2021-11-18T18:30:01.005868Z",
     "shell.execute_reply": "2021-11-18T18:30:01.005093Z",
     "shell.execute_reply.started": "2021-11-18T18:30:00.907917Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# RobustScaler is less prone to outliers.\n",
    "rob_scaler = RobustScaler()\n",
    "\n",
    "df['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\n",
    "df['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\n",
    "\n",
    "df.drop(['Time','Amount'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:01.538552Z",
     "iopub.status.busy": "2021-11-18T18:30:01.538245Z",
     "iopub.status.idle": "2021-11-18T18:30:01.590942Z",
     "shell.execute_reply": "2021-11-18T18:30:01.590175Z",
     "shell.execute_reply.started": "2021-11-18T18:30:01.538524Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scaled_amount</th>\n",
       "      <th>scaled_time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V20</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.783274</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.251412</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.269825</td>\n",
       "      <td>-0.994983</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069083</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.983721</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.524980</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.418291</td>\n",
       "      <td>-0.994972</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.208038</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.670579</td>\n",
       "      <td>-0.994960</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.408542</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   scaled_amount  scaled_time        V1        V2        V3        V4  \\\n",
       "0       1.783274    -0.994983 -1.359807 -0.072781  2.536347  1.378155   \n",
       "1      -0.269825    -0.994983  1.191857  0.266151  0.166480  0.448154   \n",
       "2       4.983721    -0.994972 -1.358354 -1.340163  1.773209  0.379780   \n",
       "3       1.418291    -0.994972 -0.966272 -0.185226  1.792993 -0.863291   \n",
       "4       0.670579    -0.994960 -1.158233  0.877737  1.548718  0.403034   \n",
       "\n",
       "         V5        V6        V7        V8  ...       V20       V21       V22  \\\n",
       "0 -0.338321  0.462388  0.239599  0.098698  ...  0.251412 -0.018307  0.277838   \n",
       "1  0.060018 -0.082361 -0.078803  0.085102  ... -0.069083 -0.225775 -0.638672   \n",
       "2 -0.503198  1.800499  0.791461  0.247676  ...  0.524980  0.247998  0.771679   \n",
       "3 -0.010309  1.247203  0.237609  0.377436  ... -0.208038 -0.108300  0.005274   \n",
       "4 -0.407193  0.095921  0.592941 -0.270533  ...  0.408542 -0.009431  0.798278   \n",
       "\n",
       "        V23       V24       V25       V26       V27       V28  Class  \n",
       "0 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0  \n",
       "1  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0  \n",
       "2  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0  \n",
       "3 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0  \n",
       "4 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_amount = df['scaled_amount']\n",
    "scaled_time = df['scaled_time']\n",
    "\n",
    "df.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\n",
    "df.insert(0, 'scaled_amount', scaled_amount)\n",
    "df.insert(1, 'scaled_time', scaled_time)\n",
    "\n",
    "# Amount and Time are Scaled!\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:02.750482Z",
     "iopub.status.busy": "2021-11-18T18:30:02.749820Z",
     "iopub.status.idle": "2021-11-18T18:30:02.906210Z",
     "shell.execute_reply": "2021-11-18T18:30:02.905394Z",
     "shell.execute_reply.started": "2021-11-18T18:30:02.750444Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(df.drop('Class', axis=1),\n",
    "                                                 df['Class'],\n",
    "                                                 test_size=0.2,\n",
    "                                                 random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:30:04.152588Z",
     "iopub.status.busy": "2021-11-18T18:30:04.152164Z",
     "iopub.status.idle": "2021-11-18T18:30:04.156576Z",
     "shell.execute_reply": "2021-11-18T18:30:04.155700Z",
     "shell.execute_reply.started": "2021-11-18T18:30:04.152549Z"
    }
   },
   "outputs": [],
   "source": [
    "cc = ClassifierCobra(machine_list='cobra')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-18T18:26:15.687990Z",
     "iopub.status.busy": "2021-11-18T18:26:15.687699Z",
     "iopub.status.idle": "2021-11-18T18:29:52.683344Z",
     "shell.execute_reply": "2021-11-18T18:29:52.682185Z",
     "shell.execute_reply.started": "2021-11-18T18:26:15.687953Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cobra SMOTE Boost f1 score: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-4175c69bb110>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Cobra SMOTE Boost f1 score: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'weighted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-26-7dc9968274f1>\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X, M, info)\u001b[0m\n\u001b[0;32m    155\u001b[0m                 \u001b[0mavg_points\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 157\u001b[1;33m                 \u001b[0mresult\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mM\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    158\u001b[0m             \u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-7dc9968274f1>\u001b[0m in \u001b[0;36mpred\u001b[1;34m(self, X, M, info)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mcount\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX_l_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmachine_predictions_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmachine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mselect\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmachine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cc.fit(x_train, y_train)\n",
    "print(\"Cobra SMOTE Boost f1 score: \", end=\"\")\n",
    "f1_score(y_test, cc.predict(x_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost f1 score: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9991727875624508"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "clf = AdaBoostClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "print(\"AdaBoost f1 score: \", end=\"\")\n",
    "f1_score(y_test, clf.predict(x_test), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
